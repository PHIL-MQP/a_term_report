@article{dong_advances_2009,
	title = {Advances in {Multi}-{Sensor} {Data} {Fusion}: {Algorithms} and {Applications}},
	volume = {9},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	shorttitle = {Advances in {Multi}-{Sensor} {Data} {Fusion}},
	url = {http://www.mdpi.com/1424-8220/9/10/7771},
	doi = {10.3390/s91007771},
	abstract = {With the development of satellite and remote sensing techniques, more and more image data from airborne/satellite sensors have become available. Multi-sensor image fusion seeks to combine information from different images to obtain more inferences than can be derived from a single sensor. In image-based application fields, image fusion has emerged as a promising research area since the end of the last century. The paper presents an overview of recent advances in multi-sensor satellite image fusion. Firstly, the most popular existing fusion algorithms are introduced, with emphasis on their recent improvements. Advances in main applications fields in remote sensing, including object identification, classification, change detection and maneuvering targets tracking, are described. Both advantages and limitations of those applications are then discussed. Recommendations are addressed, including: (1) Improvements of fusion algorithms; (2) Development of “algorithm fusion” methods; (3) Establishment of an automatic quality assessment scheme.},
	language = {en},
	number = {10},
	journal = {Sensors},
	author = {Dong, Jiang and Zhuang, Dafang and Huang, Yaohuan and Fu, Jingying},
	month = sep,
	year = {2009},
	keywords = {data fusion, multi-sensor, remote sensing},
	pages = {7771--7784},
	file = {Full Text PDF:/home/peter/Zotero/storage/NI3L52DN/Dong et al. - 2009 - Advances in Multi-Sensor Data Fusion Algorithms a.pdf:application/pdf;Snapshot:/home/peter/Zotero/storage/YM92FUXG/htm.html:text/html}
}

@inproceedings{llinas_introduction_1998,
	title = {An introduction to multi-sensor data fusion},
	volume = {6},
	doi = {10.1109/ISCAS.1998.705329},
	abstract = {Multi-sensor data fusion is an emerging technology applied to Department of Defense (DoD) areas such as automated target recognition, battlefield surveillance, and guidance and control of autonomous vehicles, and to non-DoD applications such as monitoring of complex machinery, medical diagnosis, and smart buildings. Techniques for multi-sensor data fusion are drawn from a wide range of areas including artificial intelligence, pattern recognition, statistical estimation, and other areas. This paper provides a tutorial on data fusion, introducing data fusion applications, process models, and identification of applicable techniques. Comments are made on the state-of-the-art in data fusion},
	booktitle = {Proceedings of the 1998 {IEEE} {International} {Symposium} on {Circuits} and {Systems}, 1998. {ISCAS} '98},
	author = {Llinas, J. and Hall, D. L.},
	month = may,
	year = {1998},
	keywords = {artificial intelligence, automated target recognition, Automatic control, autonomous vehicles, battlefield surveillance, Biomedical monitoring, Computerized monitoring, Condition monitoring, DoD areas, Intelligent vehicles, medical diagnosis, military systems, Mobile robots, monitoring, multi-sensor data fusion, Navigation, pattern recognition, process models, Remotely operated vehicles, sensor fusion, smart buildings, statistical estimation, Surveillance, Target recognition, target tracking, weapons},
	pages = {537--540 vol.6},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/6APZHB47/705329.html:text/html}
}

@article{whitehouse_practical_2007,
	title = {A {Practical} {Evaluation} of {Radio} {Signal} {Strength} for {Ranging}-based {Localization}},
	volume = {11},
	issn = {1559-1662},
	url = {http://doi.acm.org/10.1145/1234822.1234829},
	doi = {10.1145/1234822.1234829},
	abstract = {Radio signal strength (RSS) is notorious for being a noisy signal that is difficult to use for ranging-based localization. In this study, we demonstrate that RSS can be used to localize a multi-hop sensor network, and we quantify the effects of various environmental factors on the resulting localization error. We achieve 4.1m error in a 49 node network deployed in a half-football field sized area, demonstrating that RSS localization can be a feasible alternative to solutions like GPS given the right conditions. However, we also show that this result is highly sensitive to subtle environmental factors such as the grass height, radio enclosure, and elevation of the nodes from the ground.},
	number = {1},
	urldate = {2017-08-30},
	journal = {SIGMOBILE Mob. Comput. Commun. Rev.},
	author = {Whitehouse, Kamin and Karlof, Chris and Culler, David},
	month = jan,
	year = {2007},
	pages = {41--52},
	file = {ACM Full Text PDF:/home/peter/Zotero/storage/LWTP3B7N/Whitehouse et al. - 2007 - A Practical Evaluation of Radio Signal Strength fo.pdf:application/pdf}
}

@article{hazas_broadband_2006,
	title = {Broadband ultrasonic location systems for improved indoor positioning},
	volume = {5},
	issn = {1536-1233},
	doi = {10.1109/TMC.2006.57},
	abstract = {Ultrasonic location systems are a popular solution for the provision of fine-grained indoor positioning data. Applications include enhanced routing for wireless networks, computer-aided navigation, and location-sensitive device behavior. However, current ultrasonic location systems suffer from limitations due to their use of narrowband transducers, This paper investigates the use of broadband ultrasound for indoor positioning systems. Broadband ultrasonic transmitter and receiver units have been developed and characterized. The utilization of these units to construct two positioning systems with different architectures serves to highlight and affirm the concrete, practical benefits of broadband ultrasound for locating people and devices indoors.},
	number = {5},
	journal = {IEEE Transactions on Mobile Computing},
	author = {Hazas, M. and Hopper, A.},
	month = may,
	year = {2006},
	keywords = {Computer networks, Navigation, Application software, broadband networks, broadband ultrasonic location systems, computer-aided navigation, Concrete, fine-grained indoor positioning data, indoor positioning systems, indoor radio, Location-dependent/sensitive, location-sensitive device behavior, Narrowband, narrowband transducers, navigation, pervasive and ubiquitous computing, receivers, Routing, support services for mobile computing., transmitters, Transmitters, ultrasonic devices, Ultrasonic imaging, Ultrasonic transducers, Wireless networks, beacon, sound},
	pages = {536--547},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/MCKCBIYM/1610595.html:text/html}
}

@article{luo_dynamic_1988,
	title = {Dynamic multi-sensor data fusion system for intelligent robots},
	volume = {4},
	issn = {0882-4967},
	doi = {10.1109/56.802},
	abstract = {The objective of the authors is to develop an intelligent robot workstation capable of integrating data from multiple sensors. The investigation is based on a Unimation PUMA 560 robot and various external sensors. These include overhead vision, eye-in-hand vision, proximity, tactile array, position, force/torque, cross-fire, overload, and slip-sensing devices. The efficient fusion of data from different sources will enable the machine to respond promptly in dealing with the `real world'. Towards this goal, the general paradigm of a sensor data fusion system has been developed, and some simulation results, as well as results from the actual implementation of certain concepts of sensor data fusion, have been demonstrated},
	number = {4},
	journal = {IEEE Journal on Robotics and Automation},
	author = {Luo, R. C. and Lin, M. H. and Scherp, R. S.},
	month = aug,
	year = {1988},
	keywords = {Control systems, artificial intelligence, Automatic control, computer vision, cross-fire sensor, eye-in-hand vision, force/torque sensor, industrial robots, intelligent robots, Intelligent robots, Intelligent sensors, Layout, multi-sensor data fusion system, overhead vision, position measurement, position sensor, proximity sensor, Robot sensing systems, Robotics and automation, Sensor fusion, Sensor systems, slip-sensing devices, tactile array, tactile sensors, Temperature sensors, Unimation PUMA 560 robot, workstations},
	pages = {386--396},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/QPQDB4ZI/802.html:text/html}
}

@inproceedings{moutinho_indoor_2013,
	series = {{IFIP} {Advances} in {Information} and {Communication} {Technology}},
	title = {Indoor {Sound} {Based} {Localization}: {Research} {Questions} and {First} {Results}},
	isbn = {978-3-642-37290-2 978-3-642-37291-9},
	shorttitle = {Indoor {Sound} {Based} {Localization}},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-37291-9_56},
	doi = {10.1007/978-3-642-37291-9_56},
	abstract = {This PhD work has the goal to develop an inexpensive, easily deployable and widely compatible localization system for indoor use, suitable for pre-installed public address sound systems, avoiding costly installations or significant architectural changes in spaces. Using the audible sound range will allow the use of low cost off-the-shelf equipment suitable for keeping a low deployment cost. The state-of-the-art presented in this paper evidences a technological void in low-cost, reliable and precise localization systems and technologies. This necessity was also confirmed by the authors in a previous project (NAVMETRO®) where no suitable technological solution was found to exist to overcome the need to automatically localize people in a public space in a reliable and precise way.Although research work is in its first steps, it already provides a thorough view on the problem while discussing some possible approaches and predicting strategies to overcome the key difficulties. Some experiments were already conducted validating some initial premises and demonstrating how to measure the signal’s time-of-flight necessary to infer on distance calculations.},
	language = {en},
	booktitle = {Technological {Innovation} for the {Internet} of {Things}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Moutinho, João and Freitas, Diamantino and Araújo, Rui Esteves},
	month = apr,
	year = {2013},
	keywords = {beacon, sound},
	pages = {521--528},
	file = {Full Text PDF:/home/peter/Zotero/storage/GYGJCHMW/Moutinho et al. - 2013 - Indoor Sound Based Localization Research Question.pdf:application/pdf;Snapshot:/home/peter/Zotero/storage/R9JFYLGX/978-3-642-37291-9_56.html:text/html}
}

@book{munoz_position_2009,
	title = {Position {Location} {Techniques} and {Applications}},
	isbn = {978-0-12-374353-4},
	abstract = {This book is the definitive guide to the techniques and applications of position location, covering both terrestrial and satellite systems. It gives all the techniques, theoretical models and algorithms that an engineer needs to improve their current location schemes and to develop future location algorithms and systems. Comprehensive coverage is given to system design trade-offs, complexity issues, and the design of efficient positioning algorithms, enabling the creation of high-performance location positioning systems. Traditional methods are also re-examined in the context of the challenges posed by reconfigurable and multi-hop networks. Applications discussed include wireless networks (WiFi, ZigBee, UMTS and DVB networks), cognitive radio and sensor and multi-hop networks. . Contains a complete guide to models, techniques and applications of position location. Includes applications to wireless networks (WiFi, ZigBee, DVB networks), cognitive radio, sensor networks and reconfigurable and multi-hop networks, demonstrating the relevance of location positioning to these 'hot' areas in research and development. Covers system design trade-offs, and the design of efficient positioning algorithms enables the creation of future location positioning systems. Provides a theoretical underpinning for understanding current position location algorithms, giving researchers a foundation to develop future algorithms},
	publisher = {Academic Press},
	author = {Munoz, David and Lara, Frantz Bouchereau and Vargas, Cesar and Enriquez-Caldera, Rogerio},
	year = {2009}
}

@inproceedings{xiao_scheme_2005,
	address = {Piscataway, NJ, USA},
	series = {{IPSN} '05},
	title = {A {Scheme} for {Robust} {Distributed} {Sensor} {Fusion} {Based} on {Average} {Consensus}},
	isbn = {978-0-7803-9202-1},
	url = {http://dl.acm.org/citation.cfm?id=1147685.1147698},
	abstract = {We consider a network of distributed sensors, where each sensor takes a linear measurement of some unknown parameters, corrupted by independent Gaussian noises. We propose a simple distributed iterative scheme, based on distributed average consensus in the network, to compute the maximum-likelihood estimate of the parameters. This scheme doesn't involve explicit point-to-point message passing or routing; instead, it diffuses information across the network by updating each node's data with a weighted average of its neighbors' data (they maintain the same data structure). At each step, every node can compute a local weighted least-squares estimate, which converges to the global maximum-likelihood solution. This scheme is robust to unreliable communication links. We show that it works in a network with dynamically changing topology, provided that the infinitely occurring communication graphs are jointly connected.},
	urldate = {2017-08-31},
	booktitle = {Proceedings of the 4th {International} {Symposium} on {Information} {Processing} in {Sensor} {Networks}},
	publisher = {IEEE Press},
	author = {Xiao, Lin and Boyd, Stephen and Lall, Sanjay},
	year = {2005},
	file = {ACM Full Text PDF:/home/peter/Zotero/storage/B2MLSYA6/Xiao et al. - 2005 - A Scheme for Robust Distributed Sensor Fusion Base.pdf:application/pdf}
}

@article{drumheller_mobile_1987,
	title = {Mobile {Robot} {Localization} {Using} {Sonar}},
	volume = {PAMI-9},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.1987.4767907},
	abstract = {This correspondence describes a method by which range data from a sonar rangefinder can be used to determine the two-dimensional position and orientation of a mobile robot inside a room. The plan of the room is modeled as a list of segments indicating the positions of walls. The algorithm works by correlating straight segments in the range data against the room model, then eliminating implausible configurations using the sonar barrier test, which exploits physical constraints on sonar data. The approach is extremely tolerant of noise and clutter. Transient objects such as furniture and people need not be included in the room model, and very noisy, low-resolution sensors can be used. The algorithm's performance is demonstrated using a Polaroid Ultrasonic Rangefinder.},
	number = {2},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Drumheller, M.},
	month = mar,
	year = {1987},
	keywords = {Mobile robots, Robot sensing systems, navigation, sonar, Sonar measurements, Sonar navigation, Vehicles, Acoustical engineering, Dead reckoning, Position measurement, Testing, Velocity measurement, mapping, map, one sensor spinning},
	pages = {325--332},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/UAQ3L9LG/4767907.html:text/html;IEEE Xplore Full Text PDF:/home/peter/Zotero/storage/L6RFVLKF/Drumheller - 1987 - Mobile Robot Localization Using Sonar.pdf:application/pdf}
}

@inproceedings{giralt_multi-level_1979,
	address = {San Francisco, CA, USA},
	series = {{IJCAI}'79},
	title = {A {Multi}-level {Planning} and {Navigation} {System} for a {Mobile} {Robot}: {A} {First} {Approach} to {HILARE}},
	isbn = {978-0-934613-47-7},
	shorttitle = {A {Multi}-level {Planning} and {Navigation} {System} for a {Mobile} {Robot}},
	url = {http://dl.acm.org/citation.cfm?id=1624861.1624936},
	abstract = {This paper describes the current state of HILARE: a modular progressively-built mobile robot aimed at general robotics research. The computer organization comprises of local mini and micro processors coupled with a remote time-shared system acting as a consulting facility. A multi-level decision-making system is presented with world models, inference rules, and algorithms particular to each level. The navigation planner uses a geometric model wherein 2-space is partitioned into polygonal areas based on perceptual and/or initial information. A cost function is proposed which provides support for optimal or E-optimal path finding.},
	urldate = {2017-09-01},
	booktitle = {Proceedings of the 6th {International} {Joint} {Conference} on {Artificial} {Intelligence} - {Volume} 1},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Giralt, Georges and Sobek, Ralph and Chatila, Raja},
	year = {1979},
	pages = {335--337}
}

@article{digiampaolo_mobile_2014,
	title = {Mobile {Robot} {Localization} {Using} the {Phase} of {Passive} {UHF} {RFID} {Signals}},
	volume = {61},
	issn = {0278-0046},
	doi = {10.1109/TIE.2013.2248333},
	abstract = {This paper presents a global localization system for an indoor autonomous vehicle equipped with odometry sensors and a radio-frequency identification (RFID) reader to interrogate tags located on the ceiling of the environment. The RFID reader can measure the phase of the signals coming from responding tags. This phase has non-univocal dependence on the distance robot tag, but in the considered frequency, it is really sensitive to a change in the position of the robot. For this reason, a multihypothesis Kalman filtering approach provides a really satisfactory performance even in the case that a very small density of tags is used: In the experimental tests, an average position estimation error of about 4 cm is achieved using only two tags for an area of about 5 m2.},
	number = {1},
	journal = {IEEE Transactions on Industrial Electronics},
	author = {DiGiampaolo, E. and Martinelli, F.},
	month = jan,
	year = {2014},
	keywords = {Mobile robots, Kalman filters, mobile robots, Accuracy, Antenna measurements, Antennas, Continuous-wave radar, estimation theory, global localization, global localization system, indoor autonomous vehicle, mobile robot localization, multihypothesis Kalman filtering, multihypothesis Kalman filtering approach, odometry sensors, passive UHF RFID signal phase, Phase measurement, position estimation error, radio frequency identification, radiofrequency identification, Radiofrequency identification, robot tag distance, UHF RFID},
	pages = {365--376},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/4GCBPH6Z/6469211.html:text/html;IEEE Xplore Full Text PDF:/home/peter/Zotero/storage/T737X48F/DiGiampaolo and Martinelli - 2014 - Mobile Robot Localization Using the Phase of Passi.pdf:application/pdf}
}

@article{saab_standalone_2011,
	title = {A {Standalone} {RFID} {Indoor} {Positioning} {System} {Using} {Passive} {Tags}},
	volume = {58},
	issn = {0278-0046},
	doi = {10.1109/TIE.2010.2055774},
	abstract = {Indoor positioning systems (IPSs) locate objects in closed structures such as office buildings, hospitals, stores, factories, and warehouses, where Global Positioning System devices generally do not work. Most available systems apply wireless concepts, optical tracking, and/or ultrasound. This paper presents a standalone IPS using radio frequency identification (RFID) technology. The concept is based on an object carrying an RFID reader module, which reads low-cost passive tags installed next to the object path. A positioning system using a Kalman filter is proposed. The inputs of the proposed algorithm are the measurements of the backscattered signal power propagated from nearby RFID tags and a tag-path position database. The proposed algorithm first estimates the location of the reader, neglecting tag-reader angle-path loss. Based on the location estimate, an iterative procedure is implemented, targeting the estimation of the tag-reader angle-path loss, where the latter is iteratively compensated from the received signal strength information measurement. Experimental results are presented, illustrating the high performance of the proposed positioning system.},
	number = {5},
	journal = {IEEE Transactions on Industrial Electronics},
	author = {Saab, S. S. and Nakad, Z. S.},
	month = may,
	year = {2011},
	keywords = {Ultrasonic imaging, Kalman filters, Position measurement, radiofrequency identification, Radiofrequency identification, backscattered signal power measurement, Buildings, Global Positioning System, Hospitals, Indoor positioning system (IPS), Iterative algorithms, iterative methods, iterative procedure, Kalman filter, localization, location estimation, Optical filters, optical tracking, passive tags, Power measurement, Production facilities, radio frequency identification technology, radionavigation, RFID indoor positioning system, signal strength information measurement, tag-path position database, tag-reader angle-path loss estimation, ultrasound, wireless concepts},
	pages = {1961--1970},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/YRS5WBPY/5504205.html:text/html;IEEE Xplore Full Text PDF:/home/peter/Zotero/storage/MENYVQUM/Saab and Nakad - 2011 - A Standalone RFID Indoor Positioning System Using .pdf:application/pdf}
}

@inproceedings{lee_mobile_2007,
	title = {Mobile robot localization using infrared light reflecting landmarks},
	doi = {10.1109/ICCAS.2007.4406984},
	abstract = {To achieve autonomous mobile robot navigation, accurate localization technique is the fundamental issue that should be addressed. This paper presents mobile robot localization using infrared reflective artificial landmarks. In order to minimize the disturbance to the user and to provide the ease of installation, the passive landmarks are used. The landmarks are made of coated film which reflects the infrared light efficiently. Infrared light is not visible, but the camera can capture the reflected infrared light. Once the artificial landmark is identified, the robot's relative position/orientation is estimated with respect to the landmark. In order to reduce the number of the required artificial landmarks for a given environment, the pan-tilt mechanism is developed together with the distortion correction algorithm.},
	booktitle = {2007 {International} {Conference} on {Control}, {Automation} and {Systems}},
	author = {Lee, Sooyong and Song, Jae-Bok},
	month = oct,
	year = {2007},
	keywords = {Mobile robots, navigation, mobile robots, mobile robot localization, Acoustic sensors, Artificial Landmark, autonomous mobile robot navigation, Cameras, CMOS image sensors, Distance measurement, distortion correction algorithm, Image Processing, infrared light reflecting landmarks, Infrared sensors, infrared spectra, Localization, Mobile Robot, Optical films, Optical reflection, pan-tilt mechanism, Radio frequency, Wearable sensors},
	pages = {674--677},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/7R5LTY37/4406984.html:text/html;IEEE Xplore Full Text PDF:/home/peter/Zotero/storage/MQVJSQW5/Lee and Song - 2007 - Mobile robot localization using infrared light ref.pdf:application/pdf}
}

@inproceedings{bahl_radar:_2000,
	title = {{RADAR}: an in-building {RF}-based user location and tracking system},
	volume = {2},
	shorttitle = {{RADAR}},
	doi = {10.1109/INFCOM.2000.832252},
	abstract = {The proliferation of mobile computing devices and local-area wireless networks has fostered a growing interest in location-aware systems and services. In this paper we present RADAR, a radio-frequency (RF)-based system for locating and tracking users inside buildings. RADAR operates by recording and processing signal strength information at multiple base stations positioned to provide overlapping coverage in the area of interest. It combines empirical measurements with signal propagation modeling to determine user location and thereby enable location-aware services and applications. We present experimental results that demonstrate the ability of RADAR to estimate user location with a high degree of accuracy},
	booktitle = {Proceedings {IEEE} {INFOCOM} 2000. {Conference} on {Computer} {Communications}. {Nineteenth} {Annual} {Joint} {Conference} of the {IEEE} {Computer} and {Communications} {Societies} ({Cat}. {No}.00CH37064)},
	author = {Bahl, P. and Padmanabhan, V. N.},
	year = {2000},
	keywords = {Computer networks, Wireless networks, Global Positioning System, Radio frequency, Base stations, in-building tracking system, local-area wireless networks, location-aware systems, mobile computing, Mobile computing, mobile computing devices, multiple base stations, overlapping coverage, RADAR, Radar signal processing, Radar tracking, radio tracking, radiowave propagation, RF-based tracking system, signal processing, Signal processing, signal propagation modeling, signal strength processing, user location, wireless LAN, Wireless LAN, beacon, rf},
	pages = {775--784 vol.2},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/3V47K9J8/832252.html:text/html;IEEE Xplore Full Text PDF:/home/peter/Zotero/storage/QV4JH7QK/Bahl and Padmanabhan - 2000 - RADAR an in-building RF-based user location and t.pdf:application/pdf}
}

@inproceedings{maeda_tracking_2004,
	title = {Tracking of user position and orientation by stereo measurement of infrared markers and orientation sensing},
	volume = {1},
	doi = {10.1109/ISWC.2004.46},
	abstract = {A real-time three-dimensional position and orientation tracking system is proposed for use with wearable augmented reality systems. The system combines infrared markers with a head-mounted stereo camera to detect the user's position, and an orientation sensor to measure the orientation of the user's head. An extended Kalman filter is employed to reduce triangulation and orientation error by integrating the signals acquired by multiple sensors. The system is evaluated through a series of experiments, and a navigation system implemented using the proposed scheme is presented. The accuracy of the system is shown to be sufficient to allow annotations and virtual objects to be overlaid on real scenes via a head-mounted display without confusion.},
	booktitle = {Eighth {International} {Symposium} on {Wearable} {Computers}},
	author = {Maeda, M. and Ogawa, T. and Kiyokawa, K. and Takemura, H.},
	month = oct,
	year = {2004},
	keywords = {Navigation, Layout, Sensor systems, remote sensing, Position measurement, Kalman filter, optical tracking, Cameras, Infrared sensors, Wearable sensors, augmented reality, Augmented reality, head-mounted display, head-mounted stereo camera, helmet mounted displays, image sensors, Infrared detectors, infrared marker, orientation sensor, orientation tracking system, Real time systems, real-time systems, real-time three-dimensional position tracking, stereo image processing, three-dimensional displays, user interfaces, wearable augmented reality},
	pages = {77--84},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/IDLAZKU2/1364693.html:text/html;IEEE Xplore Full Text PDF:/home/peter/Zotero/storage/VFRDCQMP/Maeda et al. - 2004 - Tracking of user position and orientation by stere.pdf:application/pdf}
}

@inproceedings{ghidary_new_1999,
	title = {A new home robot positioning system ({HRPS}) using {IR} switched multi ultrasonic sensors},
	volume = {4},
	doi = {10.1109/ICSMC.1999.812496},
	abstract = {We propose a very fast measuring system for the location of a mobile robot in an indoor environment. The proposed localization method utilizes ultrasonic and infrared signals simultaneously. The transmitter, which is mounted on the mobile robot, transmits both ultrasonic and infrared signals at the same time. The receivers, which are located at fixed points in the ceiling of the room use the received infrared signal as a trigger to measure the time of flight of the ultrasonic signal. The location of the robot is computed by measuring its distance from three receivers. The heading of the robot is computed by measuring its position in two successive points while the robot moves from one point to the other. The performance and validity of this system are evaluated using one transmitter and six receivers located in a 6 m×4 m room. The positioning error is less than 5 cm},
	booktitle = {1999 {IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics}, 1999. {IEEE} {SMC} '99 {Conference} {Proceedings}},
	author = {Ghidary, S. S. and Tani, T. and Takamori, T. and Hattori, M.},
	year = {1999},
	keywords = {Mobile robots, position measurement, Robot sensing systems, Sensor systems, mobile robots, Orbital robotics, Dead reckoning, Global Positioning System, Infrared sensors, home robot positioning system, indoor environment, infrared detectors, infrared signals, IR switched multi ultrasonic sensors, localization method, Optical receivers, path planning, position control, positioning error, Satellite navigation systems, time of flight measurement, ultrasonic signals, ultrasonic transducers, Ultrasonic variables measurement, beacon, sound, ir},
	pages = {737--741 vol.4},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/4FCX3QZK/812496.html:text/html;IEEE Xplore Full Text PDF:/home/peter/Zotero/storage/I58G9QIT/Ghidary et al. - 1999 - A new home robot positioning system (HRPS) using I.pdf:application/pdf}
}

@inproceedings{kourogi_personal_2003,
	address = {Washington, DC, USA},
	series = {{ISMAR} '03},
	title = {Personal {Positioning} {Based} on {Walking} {Locomotion} {Analysis} with {Self}-{Contained} {Sensors} and a {Wearable} {Camera}},
	isbn = {978-0-7695-2006-3},
	url = {http://dl.acm.org/citation.cfm?id=946248.946806},
	abstract = {In this paper, we propose a method of personalpositioning for a wearable Augmented Reality (AR)system that allows a user to freely move around indoorsand outdoors.The user is equipped with self-containedsensors, a wearable camera, an inertial headtracker and display.The method is based on sensorfusion of estimates for relative displacement causedby human walking locomotion and estimates for absoluteposition and orientation within a Kalman filteringframework.The former is based on intensive analysisof human walking behavior using self-containedsensors.The latter is based on image matching ofvideo frames from a wearable camera with an imagedatabase that was prepared beforehand.},
	urldate = {2017-09-06},
	booktitle = {Proceedings of the 2Nd {IEEE}/{ACM} {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	publisher = {IEEE Computer Society},
	author = {Kourogi, Masakatsu and Kurata, Takeshi},
	year = {2003},
	keywords = {sensor fusion, human walking analysis, pedometer, personal positioning},
	pages = {103--},
	file = {ACM Full Text PDF:/home/peter/Zotero/storage/ZFFM2KHS/Kourogi and Kurata - 2003 - Personal Positioning Based on Walking Locomotion A.pdf:application/pdf}
}

@inproceedings{kleeman_optimal_1992,
	title = {Optimal estimation of position and heading for mobile robots using ultrasonic beacons and dead-reckoning},
	doi = {10.1109/ROBOT.1992.220053},
	abstract = {An active beacon localization system that estimates position and heading for a mobile robot is described. An iterated extended Kalman filter was applied to the beacon and dead-reckoning data to estimate optimal values of position and heading, given a model for the localizer and robot motion. The author describes the implementation and experimental results of the localization system. Position and heading angle updates were calculated in real time every 150 ms with a measured standard deviation of path error of 40 mm in a 12 m2 workspace},
	booktitle = {Proceedings 1992 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Kleeman, L.},
	month = may,
	year = {1992},
	keywords = {Mobile robots, Intelligent robots, navigation, Kalman filters, mobile robots, sonar, Vehicles, Position measurement, position control, active beacon localization, dead-reckoning, Error correction, heading estimation, iterated extended Kalman filter, Measurement standards, Motion estimation, path error, position estimation, Robot motion, Systems engineering and theory, ultrasonic beacons, Wheels, sound},
	pages = {2582--2587 vol.3},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/E637XLPS/220053.html:text/html;IEEE Xplore Full Text PDF:/home/peter/Zotero/storage/6QURG5WB/Kleeman - 1992 - Optimal estimation of position and heading for mob.pdf:application/pdf}
}

@inproceedings{yucel_development_2012,
	title = {Development of indoor positioning system with ultrasonic and infrared signals},
	doi = {10.1109/INISTA.2012.6246983},
	abstract = {Position measurement is one of the primal problems in wide range of applications such as air/land/marine vehicles tracking, automation systems, and equipment tracking in medical sector, robotics and sensor networks. Location information in outdoor application can be easily obtained from well-known systems such as GPS and GLONASS. Since GPS signal is not available in indoor area, several positioning systems have been developed for. But there is not a consensus for indoor positioning systems like the outdoor. In this study, a positioning system that uses ultrasonic and infrared signals is designed and implemented. The system is tested in 4m2 coverage range and it is observed that the maximum absolute error is less than +/-2 cm.},
	booktitle = {2012 {International} {Symposium} on {Innovations} in {Intelligent} {Systems} and {Applications}},
	author = {Yucel, H. and Edizkan, R. and Ozkir, T. and Yazici, A.},
	month = jul,
	year = {2012},
	keywords = {position measurement, Robot sensing systems, Transmitters, Global Positioning System, Radio frequency, infrared signals, ultrasonic signals, Ultrasonic variables measurement, Acoustics, automation systems, distance measurement, equipment tracking, GLONASS, GPS, Indoor positioning, indoor positioning system, location information, Mobile communication, Receivers, sensor networks, Time of Flight, Ultrasonic-IR signal based localization, vehicles tracking, beacon, sound, ir},
	pages = {1--4},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/YGLUU4GA/6246983.html:text/html;IEEE Xplore Full Text PDF:/home/peter/Zotero/storage/K7JCUXX8/Yucel et al. - 2012 - Development of indoor positioning system with ultr.pdf:application/pdf}
}

@article{ward_new_1997,
	title = {A new location technique for the active office},
	volume = {4},
	issn = {1070-9916},
	doi = {10.1109/98.626982},
	abstract = {Configuration of the computing and communications systems found at home and in the workplace is a complex task that currently requires the attention of the user. Researchers have begun to examine computers that would autonomously change their functionality based on observations of who or what was around them. By determining their context, using input from sensor systems distributed throughout the environment, computing devices could personalize themselves to their current user, adapt their behaviour according to their location, or react to their surroundings. The authors present a novel sensor system, suitable for large-scale deployment in indoor environments, which allows the locations of people and equipment to be accurately determined. We also describe some of the context-aware applications that might make use of this fine-grained location information},
	number = {5},
	journal = {IEEE Personal Communications},
	author = {Ward, A. and Jones, A. and Hopper, A.},
	month = oct,
	year = {1997},
	keywords = {Computerized monitoring, Application software, Sensor phenomena and characterization, Infrared sensors, location information, active office, building, communications systems, Computer applications, computing devices, computing systems, context aware applications, indoor environments, Laboratories, location aware computing, location technique, office automation, office environment, Personal digital assistants, Personnel, Pervasive computing, Printers, radio direction-finding, radio transmitters, sensor system, sensor systems, sensors, wireless transmitter, beacon, sound},
	pages = {42--47},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/K3UT4VEW/626982.html:text/html;IEEE Xplore Full Text PDF:/home/peter/Zotero/storage/EVH4THDU/Ward et al. - 1997 - A new location technique for the active office.pdf:application/pdf}
}

@inproceedings{kim_advanced_2008,
	title = {Advanced indoor localization using ultrasonic sensor and digital compass},
	doi = {10.1109/ICCAS.2008.4694553},
	abstract = {Several kinds of indoor localization systems have been developed for estimating objects position lately. They are classified according to the environment, the purpose of application, the media type and so on. In this paper, we propose an improved beacon system, having the ultrasonic media type, which can be used for indoor localization; Moreover it can estimate the direction of a mobile object by using a digital compass. However it is very hard for the indoor localization system using ultrasonic sensors to achieve much highly precise localization for mobile objects since the ultrasonic sensor is highly sensitive to noises and external shocks. In order to overcome this problem, we adopt a bandpass-filter to protect ultrasonic sensor from another frequency generated by noise and external shocks. In addition, the multi-modulation of ultrasonic sensors - using two ultrasonic sensors with different frequencies - improves the sampling rate of this system. And we present the application of Unscented Kalman Filter to improve the localization performance of our indoor mobile localization system.},
	booktitle = {2008 {International} {Conference} on {Control}, {Automation} and {Systems}},
	author = {Kim, Hong-Shik and Choi, Jong-Suk},
	month = oct,
	year = {2008},
	keywords = {Automatic control, Robotics and automation, Sensor systems, Kalman filters, Radio frequency, position control, ultrasonic transducers, radio direction-finding, band-pass filters, bandpass-filter, beacon system, compasses, digital compass, Electric shock, indoor communication, Indoor GPS, indoor localization, Indoor localization, mobile object, Multi ultrasonic sensor, Noise generators, objects position estimation, Protection, Sampling methods, Signal detection, ultrasonic media type, ultrasonic sensor, Ultrasound sensor, unscented Kalman filter, Unscented Kalman Filter, beacon, sound},
	pages = {223--226},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/M7BS7939/4694553.html:text/html;IEEE Xplore Full Text PDF:/home/peter/Zotero/storage/LY4X6S75/Kim and Choi - 2008 - Advanced indoor localization using ultrasonic sens.pdf:application/pdf}
}

@inproceedings{smith_tracking_2004,
	address = {New York, NY, USA},
	series = {{MobiSys} '04},
	title = {Tracking {Moving} {Devices} with the {Cricket} {Location} {System}},
	isbn = {978-1-58113-793-4},
	url = {http://doi.acm.org/10.1145/990064.990088},
	doi = {10.1145/990064.990088},
	abstract = {We study the problem of tracking a moving device under two indoor location architectures: an active mobile architecture and a passive mobile architecture. In the former, the infrastructure has receivers at known locations, which estimate distances to a mobile device based on an active transmission from the device. In the latter, the infrastructure has active beacons that periodically transmit signals to a passively listening mobile device, which in turn estimates distances to the beacons. Because the active mobile architecture receives simultaneous distance estimates at multiple receivers from the mobile device, it is likely to perform better tracking than the passive mobile system in which the device obtains only one distance estimate at a time and may have moved between successive estimates. However, an passive mobile system scales better with the number of mobile devices and puts users in control of whether their whereabouts are tracked.We answer the following question: How do the two architectures compare in tracking performance? We find that the active mobile architecture performs better at tracking, but that the passive mobile architecture has acceptable performance; moreover, we devise a hybrid approach that preserves the benefits of the passive mobile architecture while simultaneously providing the same performance as an active mobile system, suggesting a viable practical solution to the three goals of scalability, privacy, and tracking agility.},
	urldate = {2017-09-12},
	booktitle = {Proceedings of the 2Nd {International} {Conference} on {Mobile} {Systems}, {Applications}, and {Services}},
	publisher = {ACM},
	author = {Smith, Adam and Balakrishnan, Hari and Goraczko, Michel and Priyantha, Nissanka},
	year = {2004},
	keywords = {tracking, cricket, location-awareness, mobility, pervasive computing, beacon, sound},
	pages = {190--202},
	file = {ACM Full Text PDF:/home/peter/Zotero/storage/2TDFVQGY/Smith et al. - 2004 - Tracking Moving Devices with the Cricket Location .pdf:application/pdf}
}

@article{liu_survey_2007,
	title = {Survey of {Wireless} {Indoor} {Positioning} {Techniques} and {Systems}},
	volume = {37},
	issn = {1094-6977},
	doi = {10.1109/TSMCC.2007.905750},
	abstract = {Wireless indoor positioning systems have become very popular in recent years. These systems have been successfully used in many applications such as asset tracking and inventory management. This paper provides an overview of the existing wireless indoor positioning solutions and attempts to classify different techniques and systems. Three typical location estimation schemes of triangulation, scene analysis, and proximity are analyzed. We also discuss location fingerprinting in detail since it is used in most current system or solutions. We then examine a set of properties by which location systems are evaluated, and apply this evaluation method to survey a number of existing systems. Comprehensive performance comparisons including accuracy, precision, complexity, scalability, robustness, and cost are presented.},
	number = {6},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	author = {Liu, H. and Darabi, H. and Banerjee, P. and Liu, J.},
	month = nov,
	year = {2007},
	keywords = {indoor radio, Robustness, Image analysis, Radio frequency, radiowave propagation, Automation, Costs, Fingerprint recognition, Indoor location sensing, Inventory management, location fingerprinting, Object detection, positioning algorithm, radio frequency (RF), Scalability, wireless indoor positioning technique, wireless localization, Wireless sensor networks},
	pages = {1067--1080},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/Q24GXI32/4343996.html:text/html;IEEE Xplore Full Text PDF:/home/peter/Zotero/storage/5Y8MRURP/Liu et al. - 2007 - Survey of Wireless Indoor Positioning Techniques a.pdf:application/pdf}
}

@article{kim_efficient_2015,
	title = {An {Efficient} {TDOA}-{Based} {Localization} {Algorithm} without {Synchronization} between {Base} {Stations}},
	volume = {11},
	issn = {1550-1477},
	url = {https://doi.org/10.1155/2015/832351},
	doi = {10.1155/2015/832351},
	abstract = {An efficient localization algorithm is proposed by utilizing the time difference of arrival (TDOA) without synchronization between base stations. Generally, a TDOA-based localization algorithm requires synchronization between base stations in order to improve the accuracy of localization. Hence, correlations using wideband signals or wire connections between base stations have been used to synchronize the base stations; however, these approaches result in additional operating costs. Thus, the proposed algorithm does not require synchronization between base stations. The TDOA equations are derived by continuously varying the locations of the source and the location of a base station. The number of packets necessary for localization is also reduced. The localization performance of the proposed algorithm is verified with Monte-Carlo simulations.},
	language = {en},
	number = {9},
	urldate = {2017-09-20},
	journal = {International Journal of Distributed Sensor Networks},
	author = {Kim, Sangdeok and Chong, Jong-Wha},
	month = sep,
	year = {2015},
	keywords = {beacon},
	pages = {832351},
	file = {SAGE PDF Full Text:/home/peter/Zotero/storage/326Y7DZE/Kim and Chong - 2015 - An Efficient TDOA-Based Localization Algorithm wit.pdf:application/pdf}
}

@article{alatise_pose_2017,
	title = {Pose {Estimation} of a {Mobile} {Robot} {Based} on {Fusion} of {IMU} {Data} and {Vision} {Data} {Using} an {Extended} {Kalman} {Filter}},
	volume = {17},
	issn = {1424-8220},
	doi = {10.3390/s17102164},
	abstract = {Using a single sensor to determine the pose estimation of a device cannot give accurate results. This paper presents a fusion of an inertial sensor of six degrees of freedom (6-DoF) which comprises the 3-axis of an accelerometer and the 3-axis of a gyroscope, and a vision to determine a low-cost and accurate position for an autonomous mobile robot. For vision, a monocular vision-based object detection algorithm speeded-up robust feature (SURF) and random sample consensus (RANSAC) algorithms were integrated and used to recognize a sample object in several images taken. As against the conventional method that depend on point-tracking, RANSAC uses an iterative method to estimate the parameters of a mathematical model from a set of captured data which contains outliers. With SURF and RANSAC, improved accuracy is certain; this is because of their ability to find interest points (features) under different viewing conditions using a Hessain matrix. This approach is proposed because of its simple implementation, low cost, and improved accuracy. With an extended Kalman filter (EKF), data from inertial sensors and a camera were fused to estimate the position and orientation of the mobile robot. All these sensors were mounted on the mobile robot to obtain an accurate localization. An indoor experiment was carried out to validate and evaluate the performance. Experimental results show that the proposed method is fast in computation, reliable and robust, and can be considered for practical applications. The performance of the experiments was verified by the ground truth data and root mean square errors (RMSEs).},
	language = {eng},
	number = {10},
	journal = {Sensors (Basel, Switzerland)},
	author = {Alatise, Mary B. and Hancke, Gerhard P.},
	month = sep,
	year = {2017},
	pmid = {28934102},
	keywords = {mobile robot, extended Kalman filter, inertial sensors, object, pose estimation, vision}
}

@misc{pozyx_pozyx_2017,
	title = {Pozyx - centimeter positioning for {Arduino}},
	url = {https://www.pozyx.io},
	abstract = {Pozyx makes indoor positioning with centimeter accuracy a reality. It's compatibility with Arduino makes it a must-have for every DIY fan.},
	urldate = {2017-10-02},
	author = {Pozyx},
	year = {2017},
	file = {Snapshot:/home/peter/Zotero/storage/37DNB2P6/www.pozyx.io.html:text/html}
}

@misc{zebra_dart_2017,
	title = {Dart {Ultra} {Wideband} {UWB} {Technology} {\textbar} {Zebra}},
	url = {http://www.zebra.com/us/en/solutions/location-solutions/enabling-technologies/dart-uwb.html},
	abstract = {Zebra's Dart Ultra Wideband (UWB) technology solutions, such as DartWand, DartTag, \& Dart Hub (RTLS) provides the lowest cost-of-ownership in the industry.},
	urldate = {2017-10-02},
	journal = {Zebra Technologies},
	author = {Zebra},
	year = {2017},
	file = {Snapshot:/home/peter/Zotero/storage/JXWHVWUX/dart-uwb.html:text/html}
}

@article{cheng_chirp_2016,
	title = {Chirp signal detection using {FFT} peak frequency difference [{Correspondence}]},
	volume = {52},
	issn = {0018-9251},
	doi = {10.1109/TAES.2016.140201},
	abstract = {A new method was proposed for chirp signal detection and estimation built on the frame-based fast Fourier transform (FFT). The proposed method uses the peak frequency difference between FFT frames to detect a chirp signal and estimate chirp rate. This approach differs from conventional methods and is easy to implement. It generates more accurate chirp rate estimation especially under a low signal-to-noise ratio. Simulation and experimental data are used to verify the proposed methods.},
	number = {3},
	journal = {IEEE Transactions on Aerospace and Electronic Systems},
	author = {Cheng, C. H. and Liou, L. L. and Tsui, J. B. and Lin, D. M.},
	month = jun,
	year = {2016},
	keywords = {Receivers, Signal detection, Chirp, chirp rate estimation, chirp signal detection, Estimation, fast Fourier transforms, FFT frames, FFT peak frequency difference, frame-based fast Fourier transform, Frequency estimation, Sensitivity, signal detection, Signal to noise ratio, signal-to-noise ratio},
	pages = {1449--1453},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/ELF75DKD/7511870.html:text/html;IEEE Xplore Full Text PDF:/home/peter/Zotero/storage/NCKS98ME/Cheng et al. - 2016 - Chirp signal detection using FFT peak frequency di.pdf:application/pdf}
}

@article{huang_model-based_1999,
	title = {A model-based sound localization system and its application to robot navigation},
	volume = {27},
	issn = {0921-8890},
	url = {http://www.sciencedirect.com/science/article/pii/S0921889099000020},
	doi = {10.1016/S0921-8890(99)00002-0},
	abstract = {This paper describes a mobile robot equipped with a real time sound localization system as well as a sonar system for obstacle detection. The sound localization method is based on a model of the precedence effect of the human auditory system to cope with echoes and reverberations. Sound localization and robot navigation experiments were conducted. The results show that the robot is capable of localizing sounding objects in a reverberant environment and approaching the objects without collisions, even when the objects were behind obstacles. Environment flexibility and error robustness of the system were discussed as well.},
	number = {4},
	urldate = {2017-10-10},
	journal = {Robotics and Autonomous Systems},
	author = {Huang, Jie and Supaongprapa, Tadawute and Terakura, Ikutaka and Wang, Fuming and Ohnishi, Noboru and Sugie, Noboru},
	month = jun,
	year = {1999},
	keywords = {Model of the precedence effect, Robot audition, Robot navigation, Sound localization, sound, mapping},
	pages = {199--209},
	file = {ScienceDirect Full Text PDF:/home/peter/Zotero/storage/ZBUWS7R7/Huang et al. - 1999 - A model-based sound localization system and its ap.pdf:application/pdf;ScienceDirect Snapshot:/home/peter/Zotero/storage/N3UUXM38/S0921889099000020.html:text/html}
}

@article{leonard_mobile_1991,
	title = {Mobile robot localization by tracking geometric beacons},
	volume = {7},
	issn = {1042-296X},
	doi = {10.1109/70.88147},
	abstract = {The application of the extended Kaman filter to the problem of mobile robot navigation in a known environment is presented. An algorithm for, model-based localization that relies on the concept of a geometric beacon, a naturally occurring environment feature that can be reliably observed in successive sensor measurements and can be accurately described in terms of a concise geometric parameterization, is developed. The algorithm is based on an extended Kalman filter that utilizes matches between observed geometric beacons and an a priori map of beacon locations. Two implementations of this navigation algorithm, both of which use sonar, are described. The first implementation uses a simple vehicle with point kinematics equipped with a single rotating sonar. The second implementation uses a `Robuter' mobile robot and six static sonar transducers to provide localization information while the vehicle moves at typical speeds of 30 cm/s},
	number = {3},
	journal = {IEEE Transactions on Robotics and Automation},
	author = {Leonard, J. J. and Durrant-Whyte, H. F.},
	month = jun,
	year = {1991},
	keywords = {Mobile robots, navigation, Kalman filters, Kaman filter, Kinematics, Maintenance, mobile robot, mobile robots, model-based localization, Motion planning, point kinematics, Robustness, Robuter, Sensor phenomena and characterization, Solid modeling, sonar, Sonar measurements, Sonar navigation, tracking, Vehicles, mapping, geometric beacon tracking, 6 fixed beacons, servo spinning sensor},
	pages = {376--382},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/XY9WH3QZ/88147.html:text/html;IEEE Xplore Full Text PDF:/home/peter/Zotero/storage/5DBAXCSV/Leonard and Durrant-Whyte - 1991 - Mobile robot localization by tracking geometric be.pdf:application/pdf}
}

@inproceedings{malagon-soldara_localization_2016,
	title = {Localization for indoor applications with a cheap sonar by particle filter estimation},
	doi = {10.1109/EATIS.2016.7520101},
	abstract = {Currently there are many robots that take place indoors with both industrial and domestic applications. Here, an accurate localization is essential to provide them with features such as autonomy and artificial intelligence. However, indoor localization is a problem not fully resolved by the scientific community. One problem of indoor environments is that the walls and ceilings block GPS (global positioning systems) signals that can provide position coordinates. Consequently, it is necessary to use feature extraction and/or measurements performed along the trajectory. Unfortunately, problems such as uncertainty arise when any measurement is made. A solution to solve such problems is a probabilistic framework with state control of the mobile robot besides making a correction step following the dynamic system progress. Hence, this work proposes a cheap sonar based on four ultrasonic sensors, to measure the distance to four landmarks on environment. The readings obtained from the sensors, combined with odometry data correspond to entries for a particle filter. Accordingly, the main contribution of this work is the attenuation of uncertainty through a cheap localization system. The algorithm uses sonar like a second point of view of environment and reduces the uncertainty at each iteration of the particle filter.},
	booktitle = {2016 8th {Euro} {American} {Conference} on {Telematics} and {Information} {Systems} ({EATIS})},
	author = {Malagon-Soldara, S. M. and Avalos-Rivera, E. D. and Rivas-Araiza, E. A.},
	month = apr,
	year = {2016},
	keywords = {Robot sensing systems, mobile robot, mobile robots, sonar, Global Positioning System, indoor environment, ultrasonic transducers, distance measurement, indoor environments, indoor localization, Bayesian inference, Entropy, feature extraction, Global Positioning Systems, GPS signals, Monte Carlo methods, odometry data, Particle filter, particle filter estimation, particle filtering (numerical methods), Particle filters, position coordinates, probabilistic framework, probability, Self-localization, Silicon compounds, Sonar, sonar signal processing, ultrasonic sensors, Uncertainty},
	pages = {1--8},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/WY8GHIED/7520101.html:text/html;IEEE Xplore Full Text PDF:/home/peter/Zotero/storage/F24KT23T/Malagon-Soldara et al. - 2016 - Localization for indoor applications with a cheap .pdf:application/pdf}
}

@article{tardos_robust_2002,
	title = {Robust {Mapping} and {Localization} in {Indoor} {Environments} {Using} {Sonar} {Data}},
	volume = {21},
	doi = {10.1177/027836402320556340},
	abstract = {In this paper we describe a new technique for the creation of featurebased stochastic maps using standard Polaroid sonar sensors. The fundamental contributions of our proposal are: (1) a perceptual grouping process that permits the robust identification and localization of environmental features, such as straight segments and corners, from the sparse and noisy sonar data; (2) a map joining technique that allows the system to build a sequence of independent constant-size stochastic maps and join them in a globally consistent and optimal way; (3) a robust mechanism to determine which features in a stochastic map correspond to the same environment feature, allowing the system to update the stochastic map accordingly, and perform tasks such as revisiting and loop closing.},
	journal = {The International Journal of Robotics Research},
	author = {Tardos, Juan and Neira, José and M. Newman, Paul and J. Leonard, John},
	month = apr,
	year = {2002},
	file = {Robust_Mapping_and_Localization_in_Indoor_Environm.pdf:/home/peter/Zotero/storage/AE9KRFI7/Robust_Mapping_and_Localization_in_Indoor_Environm.pdf:application/pdf;Snapshot:/home/peter/Zotero/storage/T4HM2XCS/2495107_Robust_Mapping_and_Localization_in_Indoor_Environments_Using_Sonar_Data.html:text/html}
}

@inproceedings{gao_understanding_2007,
	title = {Understanding 2D-{BarCode} {Technology} and {Applications} in {M}-{Commerce} - {Design} and {Implementation} of {A} 2D {Barcode} {Processing} {Solution}},
	volume = {2},
	doi = {10.1109/COMPSAC.2007.229},
	abstract = {With the swift increase of the number of mobile device users, more wireless information services and mobile commerce applications are needed. Since various barcodes have been used for decades as a very effective means in many traditional commerce systems, today people are looking for innovative solutions to use barcodes in the wireless world. Recently, the mobile industry began to pay more attention to barcode applications in m-commerce because 2D-barcodes not only provide a simple and inexpensive method to present diverse commerce data, but also improve mobile user experience by reducing their inputs. This paper first discusses 2D-barcode concepts, types and classifications, major technology players, and applications in mobile commerce. Then, it reports a research project to develop a 2D-barcode processing solution to support mobile applications. Moreover, the paper also presents the application examples, and case study using the solution.},
	booktitle = {31st {Annual} {International} {Computer} {Software} and {Applications} {Conference} ({COMPSAC} 2007)},
	author = {Gao, J. Z. and Prakash, L. and Jagatesan, R.},
	month = jul,
	year = {2007},
	keywords = {Application software, Buildings, mobile computing, Mobile computing, 2D-barcode, 2D-barcode processing, 2D-barcode technology, and 2D-Barcode enabled mobile applications., bar codes, Business, Design engineering, electronic commerce, Encoding, mobile commerce, Monitoring, Process design, Rail transportation, Space technology, technology},
	pages = {49--56},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/VSSGLGI7/4291101.html:text/html;IEEE Xplore Full Text PDF:/home/peter/Zotero/storage/LKMHXUUF/Gao et al. - 2007 - Understanding 2D-BarCode Technology and Applicatio.pdf:application/pdf}
}

@misc{jo_mono_2015,
	title = {Mono or {Colour}?},
	url = {https://www.atik-cameras.com/news/mono-colour/},
	abstract = {CCD cameras for astrophotography are often available in both monochrome and one-shot colour versions, so how do you choose between the two?},
	urldate = {2017-09-05},
	journal = {Atik Cameras},
	author = {Jo},
	month = jan,
	year = {2015},
	file = {Snapshot:/home/peter/Zotero/storage/LZPU7U3M/mono-colour.html:text/html}
}

@article{huh_mobile_2007,
	title = {Mobile {Robot} {Exploration} in {Indoor} {Environment} {Using} {Topological} {Structure} with {Invisible} {Barcodes}},
	volume = {29},
	issn = {1225-6463, 2233-7326},
	url = {https://etrij.etri.re.kr/etrij/journal/article/article.do?volume=29&issue=&page=189},
	doi = {10.4218/etrij.07.0106.0066},
	language = {English},
	number = {2},
	urldate = {2017-09-12},
	journal = {ETRI Journal},
	author = {Huh, Jinwook and Chung, Woong Sik and Nam, Sang Yep and Chung, Wan Kyun},
	month = apr,
	year = {2007},
	pages = {189--200},
	file = {Full Text PDF:/home/peter/Zotero/storage/LK5W74J9/Huh et al. - 2007 - Mobile Robot Exploration in Indoor Environment Usi.pdf:application/pdf}
}

@inproceedings{lin_localization_2004,
	title = {Localization of mobile robot based on {ID} tag and {WEB} camera},
	volume = {2},
	doi = {10.1109/RAMECH.2004.1438029},
	abstract = {Localization is one of the most important fundament for mobile robot. A localization system with low cost, easy accomplishment, simplicity, effectiveness and robustness is the aim of researchers all the time. Here, we proposed a novel method for localization of mobile robot using ID tag and Web camera. In our method, the path map in an indoor environment is expressed with node tree, every node is represented with two landmarks: ID tag and card with the same colour. Pairs of two landmarks are affixed to ceiling of distinct locations, and the middle point of every pair of landmarks in a node indicates the absolute position or the node because of the unique ID of tag, the absolute position of mobile robot can be expressed with the absolute position of node and, position and orientation relative to this node. Localization is implemented with two steps: detecting ID tag in one node with RF communication and measuring position and orientation of mobile robot relative to this node with camera. In this paper, related works are summarized and the advantages of our method are introduced, the scheme of system is described in detail, a fast image processing algorithm for extracting landmarks from background and strategies for system robustness are discussed. Localization experiments show that with this method the errors or relative position and orientation are less than 2.5 cm and 2.5 degree. Navigation showed us that localization with ID tag and Web camera is feasible for navigation in indoor environment. At last, strategies for improving system are discussed.},
	booktitle = {{IEEE} {Conference} on {Robotics}, {Automation} and {Mechatronics}, 2004.},
	author = {Lin, Weiguo and Jia, Songmin and Abe, T. and Takase, K.},
	month = dec,
	year = {2004},
	keywords = {Mobile robots, Navigation, position measurement, mobile robots, Robustness, Position measurement, mobile robot localization, Cameras, Radio frequency, indoor environment, path planning, Mobile communication, Costs, feature extraction, fast image processing algorithm, ID tag detection, Indoor environments, landmark extraction, path map, RF communication, robot vision, Robot vision systems, Web camera},
	pages = {851--856 vol.2},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/AMTWQH76/1438029.html:text/html;IEEE Xplore Full Text PDF:/home/peter/Zotero/storage/E87NJF3A/Lin et al. - 2004 - Localization of mobile robot based on ID tag and W.pdf:application/pdf}
}

@inproceedings{parikh_localization_2008,
	title = {Localization and {Segmentation} of {A} 2D {High} {Capacity} {Color} {Barcode}},
	doi = {10.1109/WACV.2008.4544033},
	abstract = {A 2D color barcode can hold much more information than a binary barcode. Barcodes are often intended for consumer use where using a cellphone, a consumer can take an image of a barcode on a product, and retrieve relevant information about the product. The barcode must be read using computer vision techniques. While a color barcode can hold more information, it makes this vision task in consumer scenarios unusually challenging. We present our approach to the localization and segmentation of a 2D color barcode in such challenging scenarios, along with its evaluation on a diverse collection of images of Microsoft's recently launched high capacity color barcode (HCCB). We exploit the unique trait of barcode reading: the barcode decoder can give the vision algorithm feedback, and develop a progressive strategy to achieve both - high accuracy in diverse scenarios as well as computational efficiency.},
	booktitle = {2008 {IEEE} {Workshop} on {Applications} of {Computer} {Vision}},
	author = {Parikh, D. and Jancke, G.},
	month = jan,
	year = {2008},
	keywords = {computer vision, Cameras, Costs, bar codes, 2D color barcode, barcode decoder, barcode image, barcode reading, barcode segmentation, binary barcode, cellphone, Cellular phones, Computational efficiency, Computer vision, computer vision techniques, Decoding, Feedback, high capacity color barcode, image colour analysis, Image retrieval, image segmentation, Image segmentation, information retrieval, Information retrieval, mark scanning equipment, vision algorithm feedback},
	pages = {1--6},
	file = {IEEE Xplore Full Text PDF:/home/peter/Zotero/storage/V6A667N9/Parikh and Jancke - 2008 - Localization and Segmentation of A 2D High Capacit.pdf:application/pdf}
}

@misc{plumridge_how_nodate,
	title = {How {Does} an {Image} {Sensor} {Work}?},
	url = {https://www.lifewire.com/what-are-image-sensors-493722},
	abstract = {Digital cameras use an image sensor to capture a photograph. The sensor works like a piece of film and there are two main types: CMOS and CCD.},
	urldate = {2017-09-05},
	journal = {Lifewire},
	author = {Plumridge, Jo}
}

@article{garrido-jurado_automatic_2014,
	title = {Automatic generation and detection of highly reliable fiducial markers under occlusion},
	volume = {47},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S0031320314000235},
	doi = {10.1016/j.patcog.2014.01.005},
	abstract = {This paper presents a fiducial marker system specially appropriated for camera pose estimation in applications such as augmented reality and robot localization. Three main contributions are presented. First, we propose an algorithm for generating configurable marker dictionaries (in size and number of bits) following a criterion to maximize the inter-marker distance and the number of bit transitions. In the process, we derive the maximum theoretical inter-marker distance that dictionaries of square binary markers can have. Second, a method for automatically detecting the markers and correcting possible errors is proposed. Third, a solution to the occlusion problem in augmented reality applications is shown. To that aim, multiple markers are combined with an occlusion mask calculated by color segmentation. The experiments conducted show that our proposal obtains dictionaries with higher inter-marker distances and lower false negative rates than state-of-the-art systems, and provides an effective solution to the occlusion problem.},
	number = {6},
	urldate = {2017-09-26},
	journal = {Pattern Recognition},
	author = {Garrido-Jurado, S. and Muñoz-Salinas, R. and Madrid-Cuevas, F. J. and Marín-Jiménez, M. J.},
	month = jun,
	year = {2014},
	keywords = {Augmented reality, Computer vision, Fiducial marker},
	pages = {2280--2292},
	file = {ScienceDirect Full Text PDF:/home/peter/Zotero/storage/WQVDICSC/Garrido-Jurado et al. - 2014 - Automatic generation and detection of highly relia.pdf:application/pdf;ScienceDirect Snapshot:/home/peter/Zotero/storage/G35S6Q2U/S0031320314000235.html:text/html}
}

@article{chen_two-stage_2013,
	title = {A two-stage quality measure for mobile phone captured 2D barcode images},
	volume = {46},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S0031320313000708},
	doi = {10.1016/j.patcog.2013.01.031},
	abstract = {2D barcodes are widely used in many commercial applications where a scanning device is normally used to capture them. When mobile phones are used to capture 2D barcodes, the obtained images are usually distorted due to cheap camera lens and sensors, handshake and poor lighting conditions. These badly distorted images require a long decoding process which results in an error message generated or wrongly decoded information. In this paper, we propose a two-stage quality measure for the mobile phone captured 2D barcodes in order to reject those poor quality images. The proposed method is based on the global bimodal distribution features and the local finder pattern detection. Experimental results on QR code images show that the proposed two-stage quality measure has 97.64\% prediction accuracy with an average run time of 110ms by rejecting distorted undecodable barcode images in advance. The proposed method also has good generalizability to “unseen” camera models and performs well under different lighting conditions. Experiments on data matrix images show that our quality measure can be extended to 2D barcode patterns with similar features.},
	number = {9},
	urldate = {2017-10-10},
	journal = {Pattern Recognition},
	author = {Chen, Changsheng and Kot, Alex C. and Yang, Huijuan},
	month = sep,
	year = {2013},
	keywords = {2D barcode, Bimodal distribution, Finder pattern, Quality measure, Support vector machine},
	pages = {2588--2598},
	file = {ScienceDirect Full Text PDF:/home/peter/Zotero/storage/DZRDKUI6/Chen et al. - 2013 - A two-stage quality measure for mobile phone captu.pdf:application/pdf;ScienceDirect Snapshot:/home/peter/Zotero/storage/WK7EF53C/S0031320313000708.html:text/html}
}

@inproceedings{yang_accurate_2010,
	title = {Accurate localization of four extreme corners for barcode images captured by mobile phones},
	doi = {10.1109/ICIP.2010.5651603},
	abstract = {In this paper, we propose a novel method to locate the four extreme corners of barcodes in the images captured by mobile phones. To achieve this goal, the two nearly-parallel outer boundary lines are firstly localized by utilizing the prior knowledge of the relative distances and angles between the lines, which are subsequently employed to obtain the initially localized corners. A novel post-localization process based on edge tracing is also proposed to further validate the initially localized corners. This is achieved by setting the constraints in maximum direction change when tracing from the current to the next candidate corners. The distinctive feature of the proposed algorithm lies in the capability of handling those curved barcode images taken by the mobile phones. Experiments conducted on a data set of 1410 images show the accuracy of the corner localization is about 92.3\% and 90.5\% for indoor and outdoor barcode images, respectively. The processing time taken is about 0.8 second using Matlab.},
	booktitle = {2010 {IEEE} {International} {Conference} on {Image} {Processing}},
	author = {Yang, H. and Jiang, X. and Kot, A. C.},
	month = sep,
	year = {2010},
	keywords = {Accuracy, edge detection, Cameras, bar codes, Decoding, 2D Barcode, corner localization, curved barcode images, edge tracing, extreme corner localization, Image edge detection, indoor barcode image, Lighting, mobile handsets, Mobile handsets, mobile phones, nearly parallel outer boundary lines, outdoor barcode image, Pixel, post localization process, post-localization},
	pages = {3897--3900},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/JGVKQ8KM/5651603.html:text/html;IEEE Xplore Full Text PDF:/home/peter/Zotero/storage/M3I7NF7U/Yang et al. - 2010 - Accurate localization of four extreme corners for .pdf:application/pdf}
}

@misc{corrigan_time_2017,
	type = {Text},
	title = {Time of {Flight} {Camera} {Sensors} {On} {Drones} {And} 10 {Terrific} {Uses}},
	copyright = {https://www.dronezon.com/},
	url = {https://www.dronezon.com/learn-about-drones-quadcopters/best-uses-for-time-of-flight-tof-camera-depth-sensor-technology-in-drones-or-ground-based/},
	abstract = {Time-of-Flight camera technology is new. ToF depth camera sensors on drones or ground based can avoid obstacles, measure volumes, recognize gestures and more},
	language = {en\_US},
	urldate = {2017-09-05},
	journal = {DroneZon},
	author = {Corrigan, Fintan},
	month = jun,
	year = {2017}
}

@inproceedings{kato_marker_1999,
	title = {Marker tracking and {HMD} calibration for a video-based augmented reality conferencing system},
	doi = {10.1109/IWAR.1999.803809},
	abstract = {We describe an augmented reality conferencing system which uses the overlay of virtual images on the real world. Remote collaborators are represented on virtual monitors which can be freely positioned about a user in space. Users can collaboratively view and interact with virtual objects using a shared virtual whiteboard. This is possible through precise virtual image registration using fast and accurate computer vision techniques and head mounted display (HMD) calibration. We propose a method for tracking fiducial markers and a calibration method for optical see-through HMD based on the marker tracking},
	booktitle = {2nd {IEEE} and {ACM} {International} {Workshop} on {Augmented} {Reality}, 1999. ({IWAR} '99) {Proceedings}},
	author = {Kato, H. and Billinghurst, M.},
	year = {1999},
	keywords = {Humans, computer vision, augmented reality, Augmented reality, Computer vision, 3D CSCW, calibration, Calibration, calibration method, Collaboration, Collaborative work, computer displays, Computer displays, Computer interfaces, fiducial markers, groupware, head mounted display, head-up displays, HMD calibration, image registration, marker tracking, optical see-through HMD, overlay, precise virtual image registration, real world, remote collaborators, shared virtual whiteboard, teleconferencing, video signal processing, video-based augmented reality conferencing system, Virtual environment, virtual images, virtual monitors, Virtual reality},
	pages = {85--94},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/XK75W4LK/803809.html:text/html;IEEE Xplore Full Text PDF:/home/peter/Zotero/storage/G2YBWHAD/Kato and Billinghurst - 1999 - Marker tracking and HMD calibration for a video-ba.pdf:application/pdf}
}

@inproceedings{sattler_fast_2011,
	title = {Fast image-based localization using direct 2D-to-3D matching},
	doi = {10.1109/ICCV.2011.6126302},
	abstract = {Recently developed Structure from Motion (SfM) reconstruction approaches enable the creation of large scale 3D models of urban scenes. These compact scene representations can then be used for accurate image-based localization, creating the need for localization approaches that are able to efficiently handle such large amounts of data. An important bottleneck is the computation of 2D-to-3D correspondences required for pose estimation. Current stateof- the-art approaches use indirect matching techniques to accelerate this search. In this paper we demonstrate that direct 2D-to-3D matching methods have a considerable potential for improving registration performance. We derive a direct matching framework based on visual vocabulary quantization and a prioritized correspondence search. Through extensive experiments, we show that our framework efficiently handles large datasets and outperforms current state-of-the-art methods.},
	booktitle = {2011 {International} {Conference} on {Computer} {Vision}},
	author = {Sattler, T. and Leibe, B. and Kobbelt, L.},
	month = nov,
	year = {2011},
	keywords = {Solid modeling, Visualization, Cameras, Estimation, Image retrieval, 2D-to-3D matching, 3D models, compact scene representations, image matching, image motion analysis, image reconstruction, image representation, image-based localization, Registers, SfM reconstruction, solid modelling, structure from motion reconstruction, Three dimensional displays},
	pages = {667--674},
	file = {IEEE Xplore Full Text PDF:/home/peter/Zotero/storage/6P8ZKTXQ/Sattler et al. - 2011 - Fast image-based localization using direct 2D-to-3.pdf:application/pdf}
}

@inproceedings{jang_color_2002,
	title = {Color landmark based self-localization for indoor mobile robots},
	volume = {1},
	doi = {10.1109/ROBOT.2002.1013492},
	abstract = {We present a simple artificial landmark model and a robust tracking algorithm for the navigation of indoor mobile robots. The landmark model is designed to have a three-dimensional structure consisting of a multi-colored planar pattern. A stochastic algorithm based on Condensation [1] tracks the landmark model robustly using the color distribution of the pattern. A new self-localization algorithm computes the location of robot with the tracked single landmark. Experimental results show that the proposed landmark model is eflective. Through extensive navigation experiments in a cluttered indoor environment, we demonstrate the feasibility of the single view based self-localization in real-time.},
	booktitle = {Proceedings 2002 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({Cat}. {No}.02CH37292)},
	author = {Jang, Gijeong and Lee, Sungho and Kweon, Inso},
	month = may,
	year = {2002},
	keywords = {Mobile robots, Navigation, Layout, Robustness, Phase measurement, Wheels, Indoor environments, Computer science, Photometry, Stochastic processes},
	pages = {1037--1042},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/RPRINHN8/1013492.html:text/html;IEEE Xplore Full Text PDF:/home/peter/Zotero/storage/TAVH2KFB/Jang et al. - 2002 - Color landmark based self-localization for indoor .pdf:application/pdf}
}

@inproceedings{hu_2d_2009,
	title = {A 2D {Barcode} {Extraction} {Method} {Based} on {Texture} {Direction} {Analysis}},
	doi = {10.1109/ICIG.2009.63},
	abstract = {Barcode extraction is an essential step in the 2D barcode reading architecture. This paper presents the development and evaluation of a new approach toward the design of 2D barcode extraction based on texture direction analysis. This new approach can be detailed as: i) threshold a gray-level image; ii) analyze the texture direction of a window which is selected within the barcode area in the image; iii) roughly locate the barcode using the proposed texture direction analysis; iv) precisely locate the barcode by applying Hough transform; iv) rectify the barcode using inverse perspective transformation and bilinear interpolation methods; v) apply various types of barcode decoder. The experimental result showed this approach is applicable to most of the 2D barcode decoders.},
	booktitle = {2009 {Fifth} {International} {Conference} on {Image} and {Graphics}},
	author = {Hu, H. and Xu, W. and Huang, Q.},
	month = sep,
	year = {2009},
	keywords = {Image analysis, feature extraction, Decoding, Computer science, 2d barcode, 2D barcode extraction method, 2D barcode reading architecture, bilinear interpolation methods, Computer graphics, direction, Educational institutions, Electronic mail, extraction, Filtering, Gabor filters, gray-level image, Hough transform, Hough transforms, image texture, Image texture analysis, interpolation, inverse perspective transformation methods, Software engineering, texture, texture direction analysis},
	pages = {759--762},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/CGFCXPNR/5437922.html:text/html;IEEE Xplore Full Text PDF:/home/peter/Zotero/storage/AYRIXQM7/Hu et al. - 2009 - A 2D Barcode Extraction Method Based on Texture Di.pdf:application/pdf}
}

@inproceedings{xu_2d_2011,
	title = {2D {Barcode} localization and motion deblurring using a flutter shutter camera},
	doi = {10.1109/WACV.2011.5711498},
	abstract = {We describe a system for localizing and deblurring motion-blurred 2D barcodes. Previous work on barcode detection and deblurring has mainly focused on 1D barcodes, and has employed traditional image acquisition which is not robust to motion blur. Our solution is based on coded exposure imaging which, as we show, enables well-posed de-convolution and decoding over a wider range of velocities. To serve this solution, we developed a simple and effective approach for 2D barcode localization under motion blur, a metric for evaluating the quality of the deblurred 2D barcodes, and an approach for motion direction estimation in coded exposure images. We tested our system on real camera images of three popular 2D barcode symbologies: Data Matrix, PDF417 and Aztec Code.},
	booktitle = {2011 {IEEE} {Workshop} on {Applications} of {Computer} {Vision} ({WACV})},
	author = {Xu, W. and McCloskey, S.},
	month = jan,
	year = {2011},
	keywords = {Cameras, Estimation, Pixel, 2D barcode localization, 2D barcode symbologies, Aztec code, barcode detection, coded exposure images, data matrix, decoding, deconvolution, flutter shutter camera, Histograms, image coding, image restoration, Measurement, motion deblurring, motion direction estimation, motion estimation, Motion segmentation, object detection, PDF417 code, traditional image acquisition},
	pages = {159--165},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/3CF9BCZ2/5711498.html:text/html;IEEE Xplore Full Text PDF:/home/peter/Zotero/storage/CQNSETAB/Xu and McCloskey - 2011 - 2D Barcode localization and motion deblurring usin.pdf:application/pdf}
}

@article{betke_mobile_1997,
	title = {Mobile robot localization using landmarks},
	volume = {13},
	issn = {1042-296X},
	doi = {10.1109/70.563647},
	abstract = {We describe an efficient method for localizing a mobile robot in an environment with landmarks. We assume that the robot can identify these landmarks and measure their bearings relative to each other. Given such noisy input, the algorithm estimates the robot's position and orientation with respect to the map of the environment. The algorithm makes efficient use of our representation of the landmarks by complex numbers. The algorithm runs in time linear in the number of landmarks. We present results of simulations and propose how to use our method for robot navigation},
	number = {2},
	journal = {IEEE Transactions on Robotics and Automation},
	author = {Betke, M. and Gurvits, L.},
	month = apr,
	year = {1997},
	keywords = {Mobile robots, Navigation, Robot sensing systems, navigation, mobile robots, Working environment noise, Position measurement, mobile robot localization, path planning, position estimation, Wheels, distance measurement, Uncertainty, Autonomous agents, Computational geometry, Goniometers, landmarks, orientation estimation, robot navigation},
	pages = {251--263},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/EZ8WE83S/563647.html:text/html}
}

@article{dias_barcode-based_2012,
	title = {Barcode-based {Localization} of {Low} {Capability} {Mobile} {Robots} in {Structured} {Environments}},
	url = {https://fenix.tecnico.ulisboa.pt/downloadFile/395144230077/Submitted.pdf},
	urldate = {2017-10-11},
	journal = {2012 International Conference on Intelligent Robots and Systems},
	author = {Dias, Duarte and Ventura, Rodrigo},
	year = {2012},
	file = {Barcode-based Localization of Low Capability Mobile Robots in Structured Environments:/home/peter/Zotero/storage/AL7AKJJ6/Submitted.pdf:application/pdf}
}

@inproceedings{kobayashi_new_2012,
	title = {A new proposal for self-localization of mobile robot by self-contained 2D barcode landmark},
	abstract = {This paper deals with a new 2D barcode based landmark system for self-localization of mobile robots. The most significant feature of the landmark proposed by the author is full self-containedness, in other words, it doesn't require any extra database nor mechanism such as internet connection because its own physical position, posture and size in the world coordinate system are all encoded in itself. In addition, thanks to using ISO/IEC 18004 standard known as “QR code” for the propsed method, code detection is considered to be suitable for robots and robust against noise. The author show some preliminary experiments including kidnapping problem.},
	booktitle = {2012 {Proceedings} of {SICE} {Annual} {Conference} ({SICE})},
	author = {Kobayashi, H.},
	month = aug,
	year = {2012},
	keywords = {Mobile robots, navigation, mobile robots, Cameras, path planning, bar codes, Robot vision systems, 2D barcode, 2D barcode based landmark system, code detection, Equations, IEC standards, Internet connection, ISO standards, ISO/IEC 18004, ISO/IEC 18004 standard, kidnapping problem, landmark, Mathematical model, mobile robot navigation, mobile robot self-localization, physical position, QR code, Robot kinematics, self localization, self-contained 2D barcode landmark, world coordinate system},
	pages = {2080--2083},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/WG3E5MNH/6318357.html:text/html;IEEE Xplore Full Text PDF:/home/peter/Zotero/storage/WXM2XYWG/Kobayashi - 2012 - A new proposal for self-localization of mobile rob.pdf:application/pdf}
}

@inproceedings{wang_apriltag_2016,
	title = {{AprilTag} 2: {Efficient} and robust fiducial detection},
	shorttitle = {{AprilTag} 2},
	url = {http://ieeexplore.ieee.org/abstract/document/7759617/},
	urldate = {2017-10-11},
	booktitle = {Intelligent {Robots} and {Systems} ({IROS}), 2016 {IEEE}/{RSJ} {International} {Conference} on},
	publisher = {IEEE},
	author = {Wang, John and Olson, Edwin},
	year = {2016},
	pages = {4193--4198},
	file = {AprilTag 2\: Efficient and robust fiducial detection:/home/peter/Zotero/storage/EFCNVBXR/wang2016iros.pdf:application/pdf}
}

@inproceedings{olson_apriltag:_2011,
	title = {{AprilTag}: {A} robust and flexible visual fiducial system},
	shorttitle = {{AprilTag}},
	url = {http://ieeexplore.ieee.org/abstract/document/5979561/},
	urldate = {2017-10-11},
	booktitle = {Robotics and {Automation} ({ICRA}), 2011 {IEEE} {International} {Conference} on},
	publisher = {IEEE},
	author = {Olson, Edwin},
	year = {2011},
	pages = {3400--3407},
	file = {AprilTag\: A robust and flexible visual fiducial system:/home/peter/Zotero/storage/TS2MYE4K/olson2011tags.pdf:application/pdf}
}

@inproceedings{atcheson_caltag:_2010,
	title = {{CALTag}: {High} {Precision} {Fiducial} {Markers} for {Camera} {Calibration}.},
	volume = {10},
	shorttitle = {{CALTag}},
	url = {https://pdfs.semanticscholar.org/2dba/e046717b058382a5a04f800405f92d040200.pdf},
	urldate = {2017-10-11},
	booktitle = {{VMV}},
	author = {Atcheson, Bradley and Heide, Felix and Heidrich, Wolfgang},
	year = {2010},
	pages = {41--48},
	file = {CALTag\: High Precision Fiducial Markers for Camera Calibration:/home/peter/Zotero/storage/QCKH89C5/e046717b058382a5a04f800405f92d040200.pdf:application/pdf}
}

@misc{odonovan_optical_2005,
	title = {Optical {Flow}: {Techniques} and {Application}},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.499.4805&rep=rep1&type=pdf},
	urldate = {2017-10-01},
	author = {O'Donovan, Peter},
	month = apr,
	year = {2005}
}

@misc{sun_optical_2008,
	title = {Optical {Flow}},
	url = {http://www.cs.princeton.edu/courses/archive/fall08/cos429/optiflow.pdf},
	urldate = {2017-09-20},
	author = {Sun, Min},
	year = {2008},
	file = {optiflow.pdf:/home/peter/Zotero/storage/SZDSWNTN/optiflow.pdf:application/pdf}
}

@misc{hass_cheap_nodate,
	title = {Cheap {LIDAR} for {Robots} - {Neato} {XV}11 - {ImpulseAdventure}},
	url = {http://www.impulseadventure.com/elec/robot-lidar-neato-xv11.html},
	urldate = {2017-10-12},
	author = {Hass, Calvin},
	file = {Cheap LIDAR for Robots - Neato XV11 - ImpulseAdventure:/home/peter/Zotero/storage/D58IU2GF/robot-lidar-neato-xv11.html:text/html}
}

@misc{lidar_uk_how_2017,
	title = {How does {LiDAR} {Work}?},
	urldate = {2017-10-03},
	author = {Lidar UK},
	year = {2017}
}

@misc{keith_lidar_2007,
	title = {{LIDAR} an {Introduction} and {Overview}},
	urldate = {2017-10-05},
	author = {Keith, Marcoe},
	year = {2007}
}

@article{ho_distance_2017,
	title = {Distance and velocity estimation using optical flow from a monocular camera},
	volume = {9},
	issn = {1756-8293},
	url = {http://dx.doi.org/10.1177/1756829317695566},
	doi = {10.1177/1756829317695566},
	abstract = {Monocular vision is increasingly used in micro air vehicles for navigation. In particular, optical flow, inspired by flying insects, is used to perceive vehicle movement with respect to the surroundings or sense changes in the environment. However, optical flow does not directly provide us the distance to an object or velocity, but the ratio of them. Thus, using optical flow in control involves nonlinearity problems which add complexity to the controller. To deal with that, we propose an algorithm that estimates distance and velocity of the vehicle based on optical flow measured from a monocular camera and the knowledge of control inputs. This algorithm applies an extended Kalman filter to state estimation and uses the estimates for landing control. We implement and test our algorithm in computer simulation and on board a Parrot AR.Drone 2.0 to demonstrate its feasibility for micro air vehicles landings. Results of the simulation and multiple flight tests show that the algorithm is able to estimate height and velocity of the micro air vehicles accurately, and achieves smooth landings with these estimates, even in windy outdoor environments.},
	language = {en},
	number = {3},
	urldate = {2017-09-06},
	journal = {International Journal of Micro Air Vehicles},
	author = {Ho, Hann Woei and de Croon, Guido CHE and Chu, Qiping},
	month = sep,
	year = {2017},
	pages = {198--208},
	file = {SAGE PDF Full Text:/home/peter/Zotero/storage/SYI8TB4A/Ho et al. - 2017 - Distance and velocity estimation using optical flo.pdf:application/pdf}
}

@article{font_characterization_2011,
	title = {Characterization of a {Low}-{Cost} {Optical} {Flow} {Sensor} {When} {Using} an {External} {Laser} as a {Direct} {Illumination} {Source}},
	volume = {11},
	issn = {1424-8220},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3252013/},
	doi = {10.3390/s111211856},
	abstract = {In this paper, a low cost optical flow sensor is combined with an external laser device to measure surface displacements and mechanical oscillations. The measurement system is based on applying coherent light to a diffuser surface and using an optical flow sensor to analyze the reflected and transferred light to estimate the displacement of the surface or the laser spot. This work is focused on the characterization of this measurement system, which can have the optical flow sensor placed at different angles and distances from the diffuser surface. The results have shown that the displacement of the diffuser surface is badly estimated when the optical mouse sensor is placed in front of the diffuser surface (angular orientation {\textgreater}150°) while the highest sensitivity is obtained when the sensor is located behind the diffuser surface and on the axis of the laser source (angular orientation 0°). In this case, the coefficient of determination of the measured displacement, R2, was very high ({\textgreater}0.99) with a relative error of less than 1.29\%. Increasing the distance between the surface and the sensor also increased the sensitivity which increases linearly, R2 = 0.99. Finally, this measurement setup was proposed to measure very low frequency mechanical oscillations applied to the laser device, up to 0.01 Hz in this work. The results have shown that increasing the distance between the surface and the optical flow sensor also increases the sensitivity and the measurement range.},
	number = {12},
	urldate = {2017-10-12},
	journal = {Sensors (Basel, Switzerland)},
	author = {Font, Davinia and Tresanchez, Marcel and Pallejà, Tomàs and Teixidó, Mercè and Palacín, Jordi},
	month = dec,
	year = {2011},
	pmid = {22247696},
	pmcid = {PMC3252013},
	pages = {11856--11870},
	file = {PubMed Central Full Text PDF:/home/peter/Zotero/storage/TEFC2NMY/Font et al. - 2011 - Characterization of a Low-Cost Optical Flow Sensor.pdf:application/pdf}
}

@misc{itseez_opencv_2017,
	title = {{OpenCV}, {Optical} {Flow}},
	url = {https://docs.opencv.org/3.2.0/d7/d8b/tutorial_py_lucas_kanade.html},
	urldate = {2017-10-12},
	author = {Itseez},
	year = {2017},
	file = {OpenCV\: Optical Flow:/home/peter/Zotero/storage/8JXJVZCN/tutorial_py_lucas_kanade.html:text/html}
}

@inproceedings{marquez_accurate_2017,
	title = {Accurate {UWB} and {IMU} based {Indoor} {Localization} for {Autonomous} {Robots}},
	shorttitle = {marquez\_uwb\_2017},
	abstract = {Real-time monitoring and tracking of mobile robots in an indoor environment is very important for numerous appli- cations. In this paper a method to accurately locate mobile robots with sensor fusion is proposed. The acceleration from an inertial measurement unit (IMU) and the 2-D coordinates received from the Ultra-Wideband(UWB) anchors are fused together in a Kalman filter to achieve an accurate location estimation. The proposed method increases robustness, scalability, and accuracy of location. The measurement results, which was obtained using the proposed fusion, show considerable improvements in accu- racy of the location estimation which can be used in different Indoor Positioning System (IPS) applications requiring precision.},
	booktitle = {{IEEE} 30th {Canadian} {Conference} on {Electrical} and {Computer} {Engineering}},
	author = {Marquez, Alvin and Tank, Brinda and Meghani, Sunil Kumar and Ahmed, Ahmed and Tepe, Kemal},
	year = {2017},
	file = {Accurate UWB and IMU based Indoor Localization for Autonomous.pdf:/home/peter/Zotero/storage/5LAJLYFD/Accurate UWB and IMU based Indoor Localization for Autonomous.pdf:application/pdf}
}

@article{barshan_inertial_2017,
	title = {Inertial {Navigation} {Systems} for {Mobile} {Robots}},
	volume = {11},
	shorttitle = {barshan\_199354},
	abstract = {A low-cost solid-state inertial navigation system
(INS) for mobile robotics applications is described. Error models
for the inertial sensors are generated and included in an Extended
Kalman Filter (EKF) for estimating the position and orientation
of a moving robot vehicle. Two Merent solid-state gyroscopes
have been evaluated for estimating the orientation of the robot.
Performance of the gyroscopes with error models is compared to
the performance when the error models are excluded from the
system. The results demonstrate that without error compensation,
the error in orientation is between 5-15"/min but can be improved
at least by a factor of 5 if an adequate error model is supplied.
Siar error models have been developed for each axis of a solid-state triaxial accelerometer and for a conducting-bubble tilt sensor which may also be used as a low-cost accelerometer. Linear
position estimation with information from accelerometers and tilt sensors is more susceptible to errors due to the double integration
process involved in estimating position. With the system described

here, the position drift rate is 1-8 cds, depending on the fre-
quency of acceleration changes. An integrated inertial platform

consisting of three gyroscopes, a triaxial accelerometer and two
tilt sensors is described. Results from tests of this platform on a large outdoor mobile robot system are described and compared to
the results obtained from the robot's own radar-based guidance
system. Like all inertial systems, the platform requires additional
information from some absolute position-sensing mechanism to
overcome long-term drift. However, the results show that with
careful and detailed modeling of error sources, low-cost inertial
sensing systems can provide valuable orientation and position
information particularly for outdoor mobile robot applications.},
	number = {3},
	journal = {IEEE TRANSACTIONS ON ROBOTICS AND AUTOMATION},
	author = {Barshan, Billur and Durrant-Whyte, H. F.},
	month = sep,
	year = {2017},
	pages = {329--350},
	file = {00388775.pdf:/home/peter/Zotero/storage/GUZNQQNL/00388775.pdf:application/pdf}
}

@misc{nasa_kalman_1999,
	title = {Kalman {Filter} {Integration} of {Modern} {Guidance} and {Navigation} {T}1C {Systems}},
	abstract = {The integration of modem guidance and navigation systems is usually performed with a sub-optimal implementation of the Kalman filter, The most difficult problem is how to develop that sub-optimal implementation when considering system modeling, algorithm design, and real hardware non-lInearities, This Lecture Series brings together a group of speakers with outstanding practical experience in the design of Integrated avionics systems and tracking mechanization.., This will provide the audience with the principles, insights, and mechanisms of real, current-day system synthesis approaches aird provide the overall background necessary for synthesizing future practical guidance and navigation systems. This introductory paper will provide a brief overview of the lectures to be presented.},
	publisher = {NASA Scientific and Technical Information Branch},
	author = {NASA},
	year = {1999},
	file = {Kalman Filter Integration of Modern Guidance and Navigation T1C Systems.pdf:/home/peter/Zotero/storage/2LDLRG9A/Kalman Filter Integration of Modern Guidance and Navigation T1C Systems.pdf:application/pdf}
}

@inproceedings{anders_mannesson_radio_2012,
	title = {{RADIO} {AND} {IMU} {BASED} {INDOOR} {POSITIONING} {AND} {TRACKING}},
	abstract = {Navigation using inertial measurement units (IMUs) is an in- teresting area of research. Due to the low cost hardware and simple implementation, the approach looks very attractive. But the performance of the IMUs to provide sub-meter ac- curacy over a longer period of time is still not sufficient, so different approaches have been adopted to increase the perfor- mance at the cost of extra hardware and/or infrastructure. Our solution is based on the use of already existing radio infras- tructure, where amplitude and phase variations in a received radio signal at the user terminal is used together with the IMU to do a tightly coupled estimation of navigation and radio sig- nal multipath components. The results show that the approach has the potential to enhance the performance of IMU based navigation significantly.},
	booktitle = {{IWSSIP}},
	author = {{Anders Mannesson} and {Muhammad Atif Yaqoob} and {Fredrik Tufvesson}},
	month = apr,
	year = {2012},
	file = {RADIO AND IMU BASED INDOOR POSITIONING AND TRACKING.pdf:/home/peter/Zotero/storage/NWTMP9VD/RADIO AND IMU BASED INDOOR POSITIONING AND TRACKING.pdf:application/pdf}
}

@article{christian_forster_imu_2015,
	title = {{IMU} {Preintegration} on {Manifold} for {Efficient} {Visual}-{Inertial} {Maximum}-a-{Posteriori} {Estimation}},
	journal = {Robotics: Science and Systems},
	author = {{Christian Forster} and {Luca Carlone} and {Frank Dellaert} and {Davide Scaramuzza}},
	year = {2015},
	file = {RSS15_Forster.pdf:/home/peter/Zotero/storage/HC8AMPR4/RSS15_Forster.pdf:application/pdf}
}

@article{hertzberg_integrating_2011,
	title = {Integrating {Generic} {Sensor} {Fusion} {Algorithms} with {Sound} {State} {Representations} through {Encapsulation} of {Manifolds}},
	journal = {Spatial Cognition. Reasoning, Action, InteractionDeutsches Forschungszentrum fur Kunstliche Intelligenz (DFKI)},
	author = {Hertzberg, Christoph and Wagner, Rene and Frese, Udo and Schroder, Lutz},
	month = jul,
	year = {2011},
	file = {Integrating Generic Sensor Fusion Algorithms with.pdf:/home/peter/Zotero/storage/WTTDNMSF/Integrating Generic Sensor Fusion Algorithms with.pdf:application/pdf}
}

@article{king_inertial_1998,
	title = {Inertial {Navigation} – {Forty} {Years} of {Evolution}},
	volume = {13},
	journal = {GEC REVIEW},
	author = {King, A.D.},
	year = {1998},
	file = {inertial_navigation_introduction.pdf:/home/peter/Zotero/storage/THJZNM2A/inertial_navigation_introduction.pdf:application/pdf}
}

@article{teslic_ekf-based_2011,
	title = {{EKF}-{Based} {Localization} of a {Wheeled} {Mobile} {Robot} in {Structured} {Environments}},
	doi = {0.1007/s10846-010-9441-8},
	abstract = {This paper deals with the problem of mobile-robot localization in struc- tured environments. The extended Kalman filter (EKF) is used to localize the four- wheeled mobile robot equipped with encoders for the wheels and a laser-range- finder (LRF) sensor. The LRF is used to scan the environment, which is described with line segments. A prediction step is performed by simulating the kinematic model of the robot. In the input noise covariance matrix of the EKF the standard deviation of each robot-wheel’s angular speed is estimated as being proportional to the wheel’s angular speed. A correction step is performed by minimizing the difference between the matched line segments from the local and global maps. If the overlapping rate between the most similar local and global line segments is below the threshold, the line segments are paired. The line parameters’ covariances, which arise from the LRF’s distance-measurement error, comprise the output noise covariance matrix of the EKF. The covariances are estimated with the method of classic least squares (LSQ). The performance of this method is tested within the localization experiment in an indoor structured environment. The good localization results prove the applicability of the method resulting from the classic LSQ for the purpose of an EKF-based localization of a mobile robot.},
	journal = {Journal of Intelligent and Robotic Systems},
	author = {Teslic, Luka and Skrjanc, Igor and Klancar, Gregor},
	month = may,
	year = {2011},
	file = {EKF-Based Localization of a Wheeled Mobile Robot.pdf:/home/peter/Zotero/storage/YHH8327T/EKF-Based Localization of a Wheeled Mobile Robot.pdf:application/pdf}
}

@incollection{yu_dynamic_2011,
	title = {Dynamic modeling and power modeling of robotic skid-steered wheeled vehicles},
	booktitle = {Mobile {Robots}-{Current} {Trends}},
	publisher = {InTech},
	author = {Yu, Wei and Collins, Emmanuel and Chuy, Oscar},
	year = {2011},
	file = {Yu et al. - 2011 - Dynamic modeling and power modeling of robotic ski.pdf:/home/peter/Zotero/storage/425TUMLN/Yu et al. - 2011 - Dynamic modeling and power modeling of robotic ski.pdf:application/pdf}
}

@inproceedings{nagatani_improvement_2007,
	title = {Improvement of the {Odometry} {Accuracy} of a {Crawler} {Vehicle} with {Consideration} of {Slippage}},
	doi = {10.1109/ROBOT.2007.363881},
	abstract = {Crawler mechanisms have the advantage of stable navigation on uneven terrain; as a result, such mechanisms have been adopted for many types of locomotion of outdoor robots, including "search and rescue robots". However, crawler mechanisms always slip when tracking curved paths, and it generates a large accumulating positioning error in vehicles as opposed to conventional wheeled mobile robots. To measure the velocity of the vehicle correctly and improve the accuracy of the odometry, consideration of crawlers' slippage is very important. In this research, we propose a more accurate odometry method for crawler vehicles. In the proposed method, the vehicle can estimate the slip ratios using information from encoders (attached to the actuators) and gyro-sensors. The validity of the method was confirmed by experiments using our crawler vehicle.},
	booktitle = {Proceedings 2007 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Nagatani, K. and Endo, D. and Yoshida, K.},
	month = apr,
	year = {2007},
	keywords = {Mobile robots, Remotely operated vehicles, Sensor systems, navigation, Velocity measurement, position control, positioning error, distance measurement, Actuators, Angular velocity, Communication system control, crawler vehicle, Crawlers, gyroscopes, gyrosensors, Land vehicles, legged locomotion, multi-robot systems, navigation stability, odometry, outdoor robot locomotion, Road vehicles, search-and-rescue robots, slippage, stability, telerobotics},
	pages = {2752--2757},
	file = {IEEE Xplore Abstract Record:/home/peter/Zotero/storage/F7JURX38/4209499.html:text/html;IEEE Xplore Full Text PDF:/home/peter/Zotero/storage/8ATKZ3J3/Nagatani et al. - 2007 - Improvement of the Odometry Accuracy of a Crawler .pdf:application/pdf}
}

@incollection{durrant-whyte_multisensor_2008,
	title = {Multisensor data fusion},
	booktitle = {Springer {Handbook} of {Robotics}},
	publisher = {Springer},
	author = {Durrant-Whyte, Hugh and Henderson, Thomas C.},
	year = {2008},
	pages = {585--610},
	file = {Advanced Reading.pdf:/home/peter/Zotero/storage/RZNSXC9M/Advanced Reading.pdf:application/pdf}
}

@inproceedings{li_extracting_2010,
	title = {Extracting general-purpose features from {LIDAR} data},
	booktitle = {Robotics and {Automation} ({ICRA}), 2010 {IEEE} {International} {Conference} on},
	publisher = {IEEE},
	author = {Li, Yangming and Olson, Edwin B.},
	year = {2010},
	pages = {1388--1393},
	file = {li2010.pdf:/home/peter/Zotero/storage/5XQJDWFF/li2010.pdf:application/pdf}
}

@article{schlichting_vehicle_2016,
	title = {{VEHICLE} {LOCALIZATION} {BY} {LIDAR} {POINT} {CORRELATION} {IMPROVED} {BY} {CHANGE} {DETECTION}},
	volume = {XLI-B1},
	issn = {2194-9034},
	url = {http://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLI-B1/703/2016/isprs-archives-XLI-B1-703-2016.pdf},
	doi = {10.5194/isprsarchives-XLI-B1-703-2016},
	language = {en},
	urldate = {2017-10-30},
	journal = {ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Schlichting, A. and Brenner, C.},
	month = jun,
	year = {2016},
	pages = {703--710},
	file = {isprs-archives-XLI-B1-703-2016.pdf:/home/peter/Zotero/storage/ANJH7EEG/isprs-archives-XLI-B1-703-2016.pdf:application/pdf}
}

@article{riisgaard_slam_2003,
	title = {{SLAM} for {Dummies}},
	volume = {22},
	number = {1-127},
	journal = {A Tutorial Approach to Simultaneous Localization and Mapping},
	author = {Riisgaard, Søren and Blas, Morten Rufus},
	year = {2003},
	pages = {126},
	file = {SLAM for dummies.pdf:/home/peter/Zotero/storage/G8XMPPNM/1aslam_blas_repo.pdf:application/pdf}
}

@inproceedings{huletski_artificial_2015,
	title = {The artificial landmark design for mobile robots localization and mapping},
	booktitle = {Open {Innovations} {Association} ({FRUCT}), 2015 17th {Conference} of},
	publisher = {IEEE},
	author = {Huletski, Arthur and Kartashov, Dmitriy and Krinkin, Kirill},
	year = {2015},
	pages = {56--61},
	file = {The Artificial Landmark Design for Mobile Robots Localization and Mapping:/home/peter/Zotero/storage/DDBIE8IV/Hul.pdf:application/pdf}
}

@incollection{lee_two-dimensional_1980,
	title = {Two-{Dimensional} {Measurement} of {Ultrasound} {Beam} {Patterns} as a {Function} of {Frequency}},
	booktitle = {Acoustical {Imaging}},
	publisher = {Springer},
	author = {Lee, Paul PK and Waag, Robert C.},
	year = {1980},
	pages = {155--165},
	file = {TWO-DIMENSIONAL MEASUREMENT OF ULTRASOUND BEAM PATTERNS AS A FUNCTION OF FREQUENCY.pdf:/home/peter/Zotero/storage/D8R7JXQG/TWO-DIMENSIONAL MEASUREMENT OF ULTRASOUND BEAM PATTERNS AS A FUNCTION OF FREQUENCY.pdf:application/pdf}
}

@article{linde_aspects_2006,
	title = {On aspects of indoor localization},
	author = {Linde, Holger},
	year = {2006},
	file = {dissertation_linde.pdf:/home/peter/Zotero/storage/MXVI2XPW/dissertation_linde.pdf:application/pdf}
}

@inproceedings{d._murthy_robust_2016,
	title = {A {Robust} {Approach} for {Improving} the {Accuracy} of {IMU} based {Indoor} {Mobile} {Robot} {Localization}},
	doi = {10.5220/0005986804360445},
	author = {D. Murthy, Suriya and Krishnan S, Srivenkata and G, Sundarrajan and Kassyap S, Kiran and Bhagwanth, Ragul and Balasubramanian, Vidhya},
	month = jan,
	year = {2016},
	pages = {436--445},
	file = {Snapshot:/home/peter/Zotero/storage/DJDSU3WK/307879311_A_Robust_Approach_for_Improving_the_Accuracy_of_IMU_based_Indoor_Mobile_Robot_Localiz.html:text/html}
}

@article{dahmen_odometry_2014,
	title = {Odometry for {Ground} {Moving} {Agents} by {Optic} {Flow} {Recorded} with {Optical} {Mouse} {Chips}},
	volume = {14},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {http://www.mdpi.com/1424-8220/14/11/21045},
	doi = {10.3390/s141121045},
	abstract = {Optical mouse chips—equipped with adequate lenses—can serve as small, light, precise, fast, and cheap motion sensors monitoring optic flow induced by self motion of an agent in a contrasted environment. We present a device that extracts self motion parameters exclusively from flow in eight mouse sensors. Four pairs of sensors with opposite azimuth are mounted on a sensor head, each individual sensor looking down with {\textbackslash}(-{\textbackslash})45{\textbackslash}({\textasciicircum}\{{\textbackslash}circ\}{\textbackslash}) elevation. The head is mounted on a carriage and is moved at constant height above a textured planar ground. The calibration procedure and tests on the precision of self motion estimates are reported.},
	language = {en},
	number = {11},
	urldate = {2017-10-30},
	journal = {Sensors},
	author = {Dahmen, Hansjürgen and Mallot, Hanspeter A.},
	month = nov,
	year = {2014},
	keywords = {odometry, multiple optical mouse sensors, optic flow},
	pages = {21045--21064},
	file = {Dahmen and Mallot - 2014 - Odometry for Ground Moving Agents by Optic Flow Re.pdf:/home/peter/Zotero/storage/NATPMJF3/Dahmen and Mallot - 2014 - Odometry for Ground Moving Agents by Optic Flow Re.pdf:application/pdf;Snapshot:/home/peter/Zotero/storage/ZVZHR279/htm.html:text/html}
}

@misc{hwymeers_example_2008,
	title = {An example factor graph},
	url = {https://commons.wikimedia.org/wiki/File:Factorgraph.jpg},
	author = {Hwymeers},
	month = nov,
	year = {2008}
}

@article{vadim_indelman_information_2013,
	title = {Information {Fusion} in {Navigation} {Systems} via {Factor} {Graph} {Based} {Incremental} {Smoothing}},
	volume = {61},
	issn = {0921-8890},
	url = {http://www.sciencedirect.com/science/article/pii/S092188901300081X},
	doi = {https://doi.org/10.1016/j.robot.2013.05.001},
	abstract = {This paper presents a new approach for high-rate information fusion in modern inertial navigation systems, that have a variety of sensors operating at dif- ferent frequencies. Optimal information fusion corresponds to calculating the maximum a posteriori estimate over the joint probability distribution function (pdf) of all states, a computationally-expensive process in the general case. Our approach consists of two key components, which yields a  exible, high-rate, near-optimal inertial navigation system. First, the joint pdf is represented us- ing a graphical model, the factor graph, that fully exploits the system sparsity and provides a plug and play capability that easily accommodates the addition and removal of measurement sources. Second, an e cient incremental infer- ence algorithm over the factor graph is applied, whose performance approaches the solution that would be obtained by a computationally-expensive batch op- timization at a fraction of the computational cost. To further aid high-rate performance, we introduce an equivalent IMU factor based on a recently de- veloped technique for IMU pre-integration, drastically reducing the number of states that must be added to the system. The proposed approach is experimen- tally validated using real IMU and imagery data that was recorded by a ground vehicle, and a statistical performance study is conducted in a simulated aerial scenario. A comparison to conventional  xed-lag smoothing demonstrates that our method provides a considerably improved trade-o  between computational complexity and performance.},
	number = {8},
	journal = {Robotics and Autonomous Systems},
	author = {{Vadim Indelman} and {Stephen Williams} and {Michael Kaess} and {Frank Dellaert}},
	year = {2013},
	keywords = {Inertial navigation, Multi-sensor fusion, Graphical models, Incremental inference, Plug and play architecture},
	pages = {721 -- 738}
}

@article{lupton_todd_visual-inertial-aided_2012,
	title = {Visual-{Inertial}-{Aided} {Navigation} for {High}-{Dynamic} {Motion} in {Built} {Environments} {Without} {Initial} {Conditions}},
	volume = {28},
	shorttitle = {lupton\_vian\_2012},
	doi = {10.1109/TRO.2011.2170332},
	abstract = {In this paper, we present a novel method to fuse observations from an inertial measurement unit (IMU) and visual sensors, such that initial conditions of the inertial integration, including gravity estimation, can be recovered quickly and in a linear manner, thus removing any need for special initialization procedures. The algorithm is implemented using a graphical simultaneous localization and mapping like approach that guarantees constant time output. This paper discusses the technical aspects of the work, including observability and the ability for the system to estimate scale in real time. Results are presented of the system, estimating the platforms position, velocity, and attitude, as well as gravity vector and sensor alignment and calibration on-line in a built environment. This paper discusses the system setup, describing the real-time integration of the IMU data with either stereo or monocular vision data. We focus on human motion for the purposes of emulating high-dynamic motion, as well as to provide a localization system for future human–robot interaction.},
	journal = {IEEE Press},
	author = {Lupton, Todd, Salah, Sukkarieh},
	month = feb,
	year = {2012},
	pages = {61--76}
}

@misc{noauthor_notitle_nodate
}

@misc{kauai_labs_inc_video_2017,
	title = {Video {Processing} {Latency} {Correction} {Algorithm}},
	url = {http://pdocs.kauailabs.com/sf2/advanced/video-processing-latency-correction-algorithm/},
	abstract = {An approach is described to correct errors in the amount of axial rotation required to align a device with a target, where the target angle was initially calculated by a processing pipeline whose pipeline delay is large enough that the robotic device may have rotated after the sample used to calculate the target angle was acquired. This approach may be used in distributed processing environments and is based on globally-accessible Timestamped IMU Orientation Histories.},
	journal = {Sensor Fusion Framework},
	author = {Kauai Labs Inc},
	year = {2017}
}